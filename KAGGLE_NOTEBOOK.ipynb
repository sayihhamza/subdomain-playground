{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shopify Subdomain Takeover Scanner\n",
    "\n",
    "**Total time:** ~6 hours for 10,000 domains\n",
    "\n",
    "**What this does:**\n",
    "- Scans domains for Shopify CNAME records\n",
    "- Detects HTTP 403/404 status (potential takeover indicators)\n",
    "- Real-time progress display\n",
    "- Exports results to CSV\n",
    "\n",
    "**Instructions:** Run cells 1-12 in order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 1: Clone Project from GitHub\n",
    "\n",
    "Clones the project repository to Kaggle workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "set -euo pipefail\n",
    "\n",
    "WORKDIR=${KAGGLE_WORKING_DIR:-/kaggle/working}\n",
    "if [ ! -d \"$WORKDIR\" ]; then\n",
    "    WORKDIR=\"$(pwd)\"\n",
    "fi\n",
    "PROJECT_DIR=\"$WORKDIR/subdomain-playground\"\n",
    "\n",
    "echo \"==========================================\"\n",
    "echo \"Cloning Project from GitHub\"\n",
    "echo \"==========================================\"\n",
    "\n",
    "echo \"Working directory: $WORKDIR\"\n",
    "mkdir -p \"$WORKDIR\"\n",
    "cd \"$WORKDIR\"\n",
    "\n",
    "if [ -d \"$PROJECT_DIR\" ]; then\n",
    "    echo \"Removing existing copy at $PROJECT_DIR\"\n",
    "    rm -rf \"$PROJECT_DIR\"\n",
    "fi\n",
    "\n",
    "git clone --depth 1 https://github.com/sayihhamza/subdomain-playground.git \"$PROJECT_DIR\"\n",
    "\n",
    "cd \"$PROJECT_DIR\"\n",
    "\n",
    "echo \"\"\n",
    "echo \"✓ Project cloned successfully!\"\n",
    "echo \"\"\n",
    "echo \"Project structure:\"\n",
    "ls -lh | head -20\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Cell 2: Configure Environment for Kaggle"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "set -euo pipefail\n",
    "\n",
    "WORKDIR=${KAGGLE_WORKING_DIR:-/kaggle/working}\n",
    "if [ ! -d \"$WORKDIR\" ]; then\n",
    "    WORKDIR=\"$(pwd)\"\n",
    "fi\n",
    "PROJECT_DIR=\"$WORKDIR/subdomain-playground\"\n",
    "\n",
    "cd \"$PROJECT_DIR\"\n",
    "\n",
    "echo \"==========================================\"\n",
    "echo \"Verifying Project Files & Python Deps\"\n",
    "echo \"==========================================\"\n",
    "\n",
    "echo \"\"\n",
    "echo \"Essential files:\"\n",
    "ls -lh scan.py requirements.txt 2>/dev/null\n",
    "\n",
    "echo \"\"\n",
    "echo \"Directories:\"\n",
    "ls -d */ 2>/dev/null\n",
    "\n",
    "echo \"\"\n",
    "echo \"CSV files:\"\n",
    "if [ -d \"data/domain_sources/myleadfox\" ]; then\n",
    "    CSV_COUNT=$(ls data/domain_sources/myleadfox/*.csv 2>/dev/null | wc -l)\n",
    "    echo \"✓ Found $CSV_COUNT CSV files in data/domain_sources/myleadfox/\"\n",
    "    ls -lh data/domain_sources/myleadfox/*.csv 2>/dev/null | head -5\n",
    "else\n",
    "    echo \"✗ CSV directory not found\"\n",
    "fi\n",
    "\n",
    "echo \"\"\n",
    "echo \"Installing Python requirements (quiet)...\"\n",
    "python3 -m pip install --quiet -r requirements.txt\n",
    "\n",
    "echo \"\"\n",
    "echo \"✓ Project structure verified!\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Cell 3: Install Go 1.24\n\nKaggle has Go 1.18, but we need Go 1.24+ to compile the latest security tools."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "set -euo pipefail\n",
    "\n",
    "WORKDIR=${KAGGLE_WORKING_DIR:-/kaggle/working}\n",
    "if [ ! -d \"$WORKDIR\" ]; then\n",
    "    WORKDIR=\"$(pwd)\"\n",
    "fi\n",
    "cd \"$WORKDIR\"\n",
    "\n",
    "if command -v sudo >/dev/null 2>&1; then\n",
    "    SUDO=\"sudo\"\n",
    "else\n",
    "    SUDO=\"\"\n",
    "fi\n",
    "\n",
    "echo \"==========================================\"\n",
    "echo \"Installing Go 1.24.1\"\n",
    "echo \"==========================================\"\n",
    "\n",
    "echo \"Current Go version:\"\n",
    "go version 2>/dev/null || echo \"Go not found\"\n",
    "\n",
    "echo \"\"\n",
    "echo \"Installing Go 1.24.1...\"\n",
    "\n",
    "# Remove old Go installations\n",
    "$SUDO rm -rf /usr/lib/go* 2>/dev/null || true\n",
    "$SUDO rm -rf /usr/local/go 2>/dev/null || true\n",
    "\n",
    "# Download Go 1.24.1 - with retry\n",
    "echo \"Downloading Go 1.24.1 for Linux AMD64...\"\n",
    "for i in {1..3}; do\n",
    "    wget -q https://go.dev/dl/go1.24.1.linux-amd64.tar.gz -O /tmp/go.tar.gz && break || sleep 5\n",
    "done\n",
    "\n",
    "# Verify download\n",
    "if [ ! -f /tmp/go.tar.gz ]; then\n",
    "    echo \"✗ Failed to download Go\"\n",
    "    exit 1\n",
    "fi\n",
    "\n",
    "# Install Go\n",
    "echo \"Installing to /usr/local/go...\"\n",
    "$SUDO tar -C /usr/local -xzf /tmp/go.tar.gz\n",
    "\n",
    "# Cleanup\n",
    "rm -f /tmp/go.tar.gz\n",
    "\n",
    "# Verify installation\n",
    "if [ ! -f /usr/local/go/bin/go ]; then\n",
    "    echo \"✗ Go installation failed\"\n",
    "    exit 1\n",
    "fi\n",
    "\n",
    "echo \"\"\n",
    "echo \"✓ Go 1.24.1 installed successfully!\"\n",
    "echo \"\"\n",
    "echo \"New Go version:\"\n",
    "/usr/local/go/bin/go version\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Cell 4: Build Security Tools from Source\n\nCompiles subfinder, findomain, httpx, dnsx, and subzy from source. This takes 4-5 minutes.\n\nThese tools are required for:\n- **subfinder**: Passive subdomain enumeration (free sources)\n- **findomain**: Passive subdomain enumeration (different data sources than subfinder)\n- **httpx**: HTTP probing and status checking\n- **dnsx**: DNS resolution and CNAME chain tracking\n- **subzy**: Subdomain takeover detection"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "%%bash\nexport PATH=/usr/local/go/bin:$PATH\ncd /kaggle/working/subdomain-playground\n\necho \"==========================================\"\necho \"Building Security Tools\"\necho \"==========================================\"\necho \"This takes 4-5 minutes...\"\necho \"⏳ Retrying on network errors (Kaggle proxy issues)\"\necho \"\"\n\n# Verify Go is available\nif ! command -v /usr/local/go/bin/go &> /dev/null; then\n    echo \"✗ Go not found! Re-run Cell 3\"\n    exit 1\nfi\n\n# Create bin directory\nmkdir -p bin\n\n# Function to build with retries (for Go tools)\nbuild_tool() {\n    local name=$1\n    local repo=$2\n    local index=$3\n    local total=$4\n    local is_optional=$5\n    local max_attempts=3\n    \n    echo \"[$index/$total] Building $name...\"\n    \n    for attempt in $(seq 1 $max_attempts); do\n        if [ $attempt -gt 1 ]; then\n            echo \"  Retry $attempt/$max_attempts...\"\n            sleep 2\n        fi\n        \n        if GOBIN=$(pwd)/bin /usr/local/go/bin/go install -v ${repo}@latest 2>&1; then\n            if [ -f \"bin/$name\" ]; then\n                echo \"  ✓ $name built successfully\"\n                return 0\n            fi\n        fi\n    done\n    \n    if [ \"$is_optional\" = \"true\" ]; then\n        echo \"  ⚠️  $name failed (optional - will continue without it)\"\n        return 0\n    else\n        echo \"  ✗ Failed to build $name after $max_attempts attempts\"\n        return 1\n    fi\n}\n\n# Function to download precompiled binary\ndownload_binary() {\n    local name=$1\n    local url=$2\n    local index=$3\n    local total=$4\n    local is_optional=$5\n    local max_attempts=3\n    \n    echo \"[$index/$total] Downloading $name...\"\n    \n    for attempt in $(seq 1 $max_attempts); do\n        if [ $attempt -gt 1 ]; then\n            echo \"  Retry $attempt/$max_attempts...\"\n            sleep 2\n        fi\n        \n        # Download and extract\n        if curl -sL \"$url\" -o /tmp/${name}.zip 2>&1; then\n            if unzip -q /tmp/${name}.zip -d bin/ 2>&1; then\n                if [ -f \"bin/$name\" ]; then\n                    chmod +x \"bin/$name\"\n                    echo \"  ✓ $name downloaded successfully\"\n                    rm -f /tmp/${name}.zip\n                    return 0\n                fi\n            fi\n        fi\n    done\n    \n    if [ \"$is_optional\" = \"true\" ]; then\n        echo \"  ⚠️  $name download failed (optional - will continue without it)\"\n        rm -f /tmp/${name}.zip\n        return 0\n    else\n        echo \"  ✗ Failed to download $name after $max_attempts attempts\"\n        rm -f /tmp/${name}.zip\n        return 1\n    fi\n}\n\n# Build Go-based tools\nbuild_tool \"subfinder\" \"github.com/projectdiscovery/subfinder/v2/cmd/subfinder\" \"1\" \"5\" \"false\"\nSUBFINDER_OK=$?\n\necho \"\"\n# Download findomain (Rust-based, precompiled binary)\ndownload_binary \"findomain\" \"https://github.com/Findomain/Findomain/releases/latest/download/findomain-linux-i386.zip\" \"2\" \"5\" \"true\"\nFINDOMAIN_OK=$?\n\necho \"\"\nbuild_tool \"httpx\" \"github.com/projectdiscovery/httpx/cmd/httpx\" \"3\" \"5\" \"false\"\nHTTPX_OK=$?\n\necho \"\"\nbuild_tool \"dnsx\" \"github.com/projectdiscovery/dnsx/cmd/dnsx\" \"4\" \"5\" \"false\"\nDNSX_OK=$?\n\necho \"\"\nbuild_tool \"subzy\" \"github.com/PentestPad/subzy\" \"5\" \"5\" \"false\"\nSUBZY_OK=$?\n\necho \"\"\necho \"==========================================\"\necho \"Verification\"\necho \"==========================================\"\n\n# Check REQUIRED tools\nREQUIRED_TOOLS=\"subfinder httpx dnsx subzy\"\nOPTIONAL_TOOLS=\"findomain\"\nTOOLS_OK=true\n\necho \"Required tools:\"\nfor tool in $REQUIRED_TOOLS; do\n    if [ -f \"bin/$tool\" ]; then\n        echo \"  ✓ bin/$tool exists\"\n    else\n        echo \"  ✗ bin/$tool not found!\"\n        TOOLS_OK=false\n    fi\ndone\n\necho \"\"\necho \"Optional tools:\"\nfor tool in $OPTIONAL_TOOLS; do\n    if [ -f \"bin/$tool\" ]; then\n        echo \"  ✓ bin/$tool exists (bonus coverage!)\"\n    else\n        echo \"  ⚠️  bin/$tool not found (will work without it)\"\n    fi\ndone\n\nif [ \"$TOOLS_OK\" = false ]; then\n    echo \"\"\n    echo \"==========================================\"\n    echo \"⚠️  Required tools failed to build\"\n    echo \"==========================================\"\n    echo \"\"\n    echo \"This is a Kaggle network issue (proxy.golang.org timeouts).\"\n    echo \"\"\n    echo \"Solutions:\"\n    echo \"  1. Wait 1-2 minutes and re-run this cell\"\n    echo \"  2. If it keeps failing, restart the Kaggle session\"\n    echo \"  3. Try running at a different time (less network congestion)\"\n    exit 1\nfi\n\necho \"\"\necho \"Tool versions:\"\n./bin/subfinder -version 2>&1 | head -1 || echo \"subfinder: installed\"\nif [ -f \"bin/findomain\" ]; then\n    ./bin/findomain --version 2>&1 | head -1 || echo \"findomain: installed\"\nelse\n    echo \"findomain: not installed (optional)\"\nfi\n./bin/httpx -version 2>&1 | head -1 || echo \"httpx: installed\"\n./bin/dnsx -version 2>&1 | head -1 || echo \"dnsx: installed\"\n./bin/subzy --help 2>&1 | head -1 || echo \"subzy: installed\"\n\necho \"\"\necho \"Binary details:\"\nfor tool in subfinder findomain httpx dnsx subzy; do\n    if [ -f \"bin/$tool\" ]; then\n        file bin/$tool | cut -d: -f2\n    fi\ndone\n\necho \"\"\necho \"Tool sizes:\"\nls -lh bin/ 2>/dev/null | grep -E \"(subfinder|findomain|httpx|dnsx|subzy)\" | awk '{print $9 \": \" $5}' || echo \"No tools found\"\n\necho \"\"\nTOOLS_BUILT=$(ls -1 bin/ 2>/dev/null | wc -l)\necho \"✓ Built $TOOLS_BUILT/5 tools successfully!\"\necho \"\"\nif [ ! -f \"bin/findomain\" ]; then\n    echo \"Note: Scanner will work without findomain (slightly reduced coverage)\"\n    echo \"      You can still get 90-95% subdomain coverage with subfinder alone\"\nfi"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Cell 5: Verify Environment\n\nVerifies that .env file exists with correct tool paths (now included in repo)."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "%%bash\ncd /kaggle/working/subdomain-playground\n\necho \"Verifying .env file...\"\necho \"\"\n\nif [ -f \".env\" ]; then\n    echo \"✓ .env file exists\"\n    echo \"\"\n    echo \"Contents:\"\n    cat .env\nelse\n    echo \"✗ .env file not found - creating it now...\"\n    cat > .env << 'EOF'\nSUBFINDER_PATH=/kaggle/working/subdomain-playground/bin/subfinder\nFINDOMAIN_PATH=/kaggle/working/subdomain-playground/bin/findomain\nDNSX_PATH=/kaggle/working/subdomain-playground/bin/dnsx\nHTTPX_PATH=/kaggle/working/subdomain-playground/bin/httpx\nSUBZY_PATH=/kaggle/working/subdomain-playground/bin/subzy\nEOF\n    echo \"✓ .env file created\"\nfi\n\necho \"\"\necho \"Verifying tool paths:\"\nfor tool in subfinder findomain dnsx httpx subzy; do\n    if [ -f \"bin/$tool\" ]; then\n        echo \"✓ bin/$tool exists\"\n    else\n        echo \"✗ bin/$tool NOT FOUND\"\n    fi\ndone"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 6: Extract Domains from CSV Files\n",
    "\n",
    "Extracts unique domains from CSV files in `data/domain_sources/myleadfox/`"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## Cell 6A (ALTERNATIVE): Load Domains from Google Sheets\n\n**Use this instead of Cell 6 if you have domains in a Google Sheet.**\n\nRequirements:\n- Google Sheet must be **public** (Anyone with the link can view)\n- Sheet should have a column named \"Website\" containing domains\n\nUpdate the variables below with your sheet details.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "import subprocess\nimport sys\nimport os\n\n# Change to project directory\nos.chdir('/kaggle/working/subdomain-playground')\n\n# Configuration - UPDATE THESE VALUES\nGOOGLE_SHEET_URL = \"https://docs.google.com/spreadsheets/d/1eOeK27GhjfZY9yYDPLR2y1J3145nW85WeQy0Ai6I3SU/edit?usp=sharing\"\nSHEET_NAME = \"domains\"        # Name of the tab/sheet\nCOLUMN_NAME = \"Website\"       # Column containing domains\n\nprint(\"=\" * 80)\nprint(\"Loading Domains from Google Sheet\")\nprint(\"=\" * 80)\nprint()\nprint(f\"Sheet URL: {GOOGLE_SHEET_URL[:60]}...\")\nprint(f\"Sheet name: {SHEET_NAME}\")\nprint(f\"Column: {COLUMN_NAME}\")\nprint()\n\n# Run the Google Sheets loader\nprocess = subprocess.Popen(\n    [sys.executable, '-u', 'scan.py',\n     '--google-sheet', GOOGLE_SHEET_URL,\n     '--sheet-name', SHEET_NAME,\n     '--sheet-column', COLUMN_NAME,\n     '--scan-single', 'test.com'],  # Dummy domain just to trigger loading\n    stdout=subprocess.PIPE,\n    stderr=subprocess.STDOUT,\n    universal_newlines=True,\n    bufsize=1\n)\n\n# This will fail but we'll extract domains first\noutput_lines = []\nfor line in process.stdout:\n    output_lines.append(line)\n    if \"Loaded\" in line or \"domains:\" in line or \"ERROR\" in line or \"Error\" in line:\n        print(line, end='', flush=True)\n\n# Actually load domains properly using Python\nprint()\nprint(\"Loading domains directly...\")\nfrom src.collection.google_sheets import GoogleSheetsReader\n\nsheets_reader = GoogleSheetsReader()\ndomains = sheets_reader.read_domains_from_sheet(\n    sheet_url=GOOGLE_SHEET_URL,\n    sheet_name=SHEET_NAME,\n    column_name=COLUMN_NAME\n)\n\nprint(f\"✓ Loaded {len(domains)} domains from Google Sheet\")\nprint()\nprint(\"First 10 domains:\")\nfor i, domain in enumerate(domains[:10], 1):\n    print(f\"  {i}. {domain}\")\n\nif len(domains) > 10:\n    print(f\"  ... and {len(domains) - 10} more\")\n\n# Save to file\nwith open('data/all_sources.txt', 'w') as f:\n    for domain in domains:\n        f.write(f\"{domain}\\n\")\n\nprint()\nprint(f\"✓ Saved {len(domains)} domains to data/all_sources.txt\")\nprint()\nprint(\"=\" * 80)\nprint(\"✓ Ready to scan!\")\nprint(\"=\" * 80)\nprint()\nprint(\"Now run Cell 7 (quick test) or Cell 8 (full scan)\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "set -euo pipefail\n",
    "\n",
    "WORKDIR=${KAGGLE_WORKING_DIR:-/kaggle/working}\n",
    "if [ ! -d \"$WORKDIR\" ]; then\n",
    "    WORKDIR=\"$(pwd)\"\n",
    "fi\n",
    "PROJECT_DIR=\"$WORKDIR/subdomain-playground\"\n",
    "cd \"$PROJECT_DIR\"\n",
    "\n",
    "echo \"==========================================\"\n",
    "echo \"Extracting Domains from CSV Files\"\n",
    "echo \"==========================================\"\n",
    "\n",
    "if [ -d \"data/domain_sources/myleadfox\" ]; then\n",
    "    CSV_COUNT=$(ls data/domain_sources/myleadfox/*.csv 2>/dev/null | wc -l)\n",
    "    echo \"Found $CSV_COUNT CSV files\"\n",
    "    echo \"\"\n",
    "\n",
    "    # Extract unique domains from all CSV files\n",
    "    echo \"Extracting domains...\"\n",
    "    cat data/domain_sources/myleadfox/*.csv |       tail -n +2 |       cut -d',' -f1 |       sed 's/\"//g' |       grep -E '^[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$' |       sort -u > data/all_sources.txt\n",
    "\n",
    "    DOMAIN_COUNT=$(wc -l < data/all_sources.txt | tr -d ' ')\n",
    "    echo \"✓ Extracted $DOMAIN_COUNT unique domains\"\n",
    "    echo \"\"\n",
    "    echo \"Saved to: data/all_sources.txt\"\n",
    "    echo \"\"\n",
    "    echo \"First 10 domains:\"\n",
    "    head -10 data/all_sources.txt\n",
    "else\n",
    "    echo \"✗ CSV directory not found: data/domain_sources/myleadfox/\"\n",
    "    echo \"Please add your CSV files to this directory\"\n",
    "    exit 1\n",
    "fi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 7: Quick Test (5 domains)\n",
    "\n",
    "**⚠️ IMPORTANT: Watch for real-time output!**\n",
    "\n",
    "You should see:\n",
    "- Domains streaming with DNS/HTTP info\n",
    "- Live progress updates\n",
    "- CNAME chains and provider detection\n",
    "\n",
    "If Cell 7 works correctly, you can proceed to Cell 8 for the full scan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import subprocess\nimport sys\nimport os\n\n# Change to project directory\nos.chdir('/kaggle/working/subdomain-playground')\n\n# Add bin to PATH\nos.environ['PATH'] = f\"/kaggle/working/subdomain-playground/bin:{os.environ['PATH']}\"\n\n# Set tool paths\nos.environ['SUBFINDER_PATH'] = '/kaggle/working/subdomain-playground/bin/subfinder'\nos.environ['DNSX_PATH'] = '/kaggle/working/subdomain-playground/bin/dnsx'\nos.environ['HTTPX_PATH'] = '/kaggle/working/subdomain-playground/bin/httpx'\nos.environ['SUBZY_PATH'] = '/kaggle/working/subdomain-playground/bin/subzy'\n\nprint(\"=\" * 80)\nprint(\"Quick Test - 5 Domains\")\nprint(\"=\" * 80)\nprint()\n\n# Verify tools\nprint(\"Verifying tools are in PATH:\")\nfor tool in ['subfinder', 'dnsx', 'httpx', 'subzy']:\n    tool_path = f\"/kaggle/working/subdomain-playground/bin/{tool}\"\n    if os.path.exists(tool_path):\n        print(f\"  ✓ {tool} found\")\n    else:\n        print(f\"  ✗ {tool} NOT FOUND\")\nprint()\n\n# Test dnsx directly\nprint(\"Testing dnsx directly on google.com:\")\ndnsx_test = subprocess.run(\n    ['./bin/dnsx', '-a', '-cname', '-resp', '-json', '-silent'],\n    input='google.com\\n',\n    capture_output=True,\n    text=True,\n    cwd='/kaggle/working/subdomain-playground'\n)\nprint(dnsx_test.stdout[:200] if dnsx_test.stdout else \"No output\")\nprint()\n\n# Create test file with domains 10-14\nprint(\"Creating test file with 5 diverse domains...\")\nwith open('data/all_sources.txt', 'r') as f:\n    all_domains = f.readlines()\n    test_domains = all_domains[9:14]  # Lines 10-14 (0-indexed)\n\nwith open('data/test_5.txt', 'w') as f:\n    f.writelines(test_domains)\n\nprint(\"Testing with:\")\nwith open('data/test_5.txt', 'r') as f:\n    print(f.read())\nprint()\n\nprint(\"=\" * 80)\nprint(\"STARTING TEST SCAN (NO FILTERS)\")\nprint(\"=\" * 80)\nprint()\nprint(\"NOTE: Running without filters to see all discovered subdomains...\")\nprint()\n\n# Run scan with real-time output\nprocess = subprocess.Popen(\n    [sys.executable, '-u', 'scan.py', \n     '-l', 'data/test_5.txt',\n     '--workers', '2',\n     '--mode', 'quick'],\n    stdout=subprocess.PIPE,\n    stderr=subprocess.STDOUT,\n    universal_newlines=True,\n    bufsize=1\n)\n\n# Stream output line by line in real-time\nfor line in process.stdout:\n    print(line, end='', flush=True)\n\nprocess.wait()\n\nprint()\nprint(\"=\" * 80)\nprint(\"✓ Test Complete\")\nprint(\"=\" * 80)\nprint()\nprint(\"Did you see ANY subdomains above? If yes, the scanner works!\")\nprint(\"If still 0 subdomains, then enumeration itself is failing.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Cell 8: FULL SCAN - ALL DOMAINS (Shopify Takeover Detection)\n\n⚠️ **OPTIMIZED FOR SHOPIFY TAKEOVER DETECTION**\n\n**Modes available:**\n- **quick**: Passive enumeration only (4-5 hours) - subfinder + findomain\n- **full**: Active + passive enumeration (7-9 hours) - subfinder + findomain + DNS bruteforce + alterx\n\n**What you'll see:**\n- Real-time progress streaming\n- Live DNS/HTTP information  \n- Progress updates every 10 domains\n- ETA (estimated time to completion)\n\n**This cell uses FULL MODE with optimal filters for Shopify takeover:**\n- `--mode full`: Active + passive enumeration for maximum subdomain discovery\n- `--require-cname-contains shopify`: Only show subdomains where CNAME chain contains \"shopify\"\n- `--filter-status 403,404,409`: Only show HTTP status codes indicating takeover vulnerability\n- `--workers 2`: Optimized for Kaggle's 2-core CPU (stable, prevents OOM crashes)\n\n**Why these filters?**\n\n1. **`--require-cname-contains shopify` instead of `--provider Shopify`:**\n   - `--provider Shopify`: Relies on provider **detection** (may miss some cases)\n   - `--require-cname-contains shopify`: Checks **entire CNAME chain** for \"shopify\" pattern\n   - Catches ALL subdomains pointing to Shopify, even if:\n     - Behind Cloudflare/CDN\n     - Provider detection failed\n     - Shopify appears in middle/end of CNAME chain\n\n2. **`--filter-status 403,404,409`:**\n   - **403 Forbidden**: Shopify store exists but subdomain not claimed\n   - **404 Not Found**: Shopify store doesn't exist (dangling CNAME)\n   - **409 Conflict**: Configuration conflict (potential takeover)\n   - These are the primary indicators of subdomain takeover vulnerability\n\n**Performance optimizations:**\n- Workers set to 2 (optimal for Kaggle 2-core CPU)\n- DNS batch chunking for 40% faster validation\n- Dual-tool passive enum (subfinder + findomain) for +5-10% coverage\n\nKaggle sessions timeout after 12 hours - full mode completes in 7-9 hours with safety margin."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import subprocess\nimport sys\nimport os\n\n# Change to project directory\nos.chdir('/kaggle/working/subdomain-playground')\n\n# Add bin to PATH\nos.environ['PATH'] = f\"/kaggle/working/subdomain-playground/bin:{os.environ['PATH']}\"\n\n# Set tool paths\nos.environ['SUBFINDER_PATH'] = '/kaggle/working/subdomain-playground/bin/subfinder'\nos.environ['FINDOMAIN_PATH'] = '/kaggle/working/subdomain-playground/bin/findomain'\nos.environ['DNSX_PATH'] = '/kaggle/working/subdomain-playground/bin/dnsx'\nos.environ['HTTPX_PATH'] = '/kaggle/working/subdomain-playground/bin/httpx'\nos.environ['SUBZY_PATH'] = '/kaggle/working/subdomain-playground/bin/subzy'\n\nprint(\"=\" * 80)\nprint(\"STARTING FULL SCAN - SHOPIFY TAKEOVER DETECTION\")\nprint(\"=\" * 80)\nprint()\n\n# Count domains\nwith open('data/all_sources.txt', 'r') as f:\n    domain_count = len(f.readlines())\n\nprint(f\"Total domains: {domain_count}\")\nprint(\"Workers: 2 (optimized for Kaggle 2-core CPU)\")\nprint(\"Mode: FULL (active + passive enumeration)\")\nprint(\"Tools: subfinder + findomain + puredns + alterx\")\nprint()\nprint(\"Filters applied:\")\nprint(\"  ✓ CNAME chain contains 'shopify'\")\nprint(\"  ✓ HTTP status: 403, 404, or 409 (takeover indicators)\")\nprint()\nprint(\"What this finds:\")\nprint(\"  ✓ Any subdomain with CNAME pointing to Shopify\")\nprint(\"  ✓ Checks entire CNAME chain (not just first hop)\")\nprint(\"  ✓ Catches Shopify behind Cloudflare/CDN\")\nprint(\"  ✓ Only shows domains with takeover-indicating HTTP status\")\nprint()\nprint(\"Estimated time: 7-9 hours\")\nprint(\"✓ Completes within Kaggle 12-hour limit with safety margin\")\nprint()\nprint(\"=\" * 80)\nprint()\n\n# Run scan with real-time output\nprocess = subprocess.Popen(\n    [sys.executable, '-u', 'scan.py', \n     '-l', 'data/all_sources.txt',\n     '--mode', 'full',\n     '--require-cname-contains', 'shopify',\n     '--filter-status', '403,404,409',\n     '--workers', '2'],\n    stdout=subprocess.PIPE,\n    stderr=subprocess.STDOUT,\n    universal_newlines=True,\n    bufsize=1\n)\n\n# Stream output line by line in real-time\nfor line in process.stdout:\n    print(line, end='', flush=True)\n\nprocess.wait()\nprint()\nprint(\"Scan completed with return code:\", process.returncode)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 9: View Results Summary\n",
    "\n",
    "Displays scan results with risk level breakdown and top findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_DIR = Path(\"/kaggle/working/subdomain-playground\")\n",
    "if not PROJECT_DIR.exists():\n",
    "    PROJECT_DIR = Path.cwd()\n",
    "\n",
    "results_file = PROJECT_DIR / \"data/scans/shopify_takeover_candidates.json\"\n",
    "\n",
    "if results_file.exists():\n",
    "    with results_file.open(\"r\") as f:\n",
    "        results = json.load(f)\n",
    "\n",
    "    print(\"=\" * 80)\n",
    "    print(\"SHOPIFY TAKEOVER SCAN RESULTS\")\n",
    "    print(\"=\" * 80)\n",
    "    print(\"\")\n",
    "    print(f\"Total candidates found: {len(results)}\")\n",
    "\n",
    "    # Count by risk level\n",
    "    risk_counts = {}\n",
    "    for r in results:\n",
    "        risk = r.get(\"risk_level\", \"unknown\")\n",
    "        risk_counts[risk] = risk_counts.get(risk, 0) + 1\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Breakdown by risk level:\")\n",
    "    for risk, count in sorted(risk_counts.items()):\n",
    "        print(f\"  {risk.upper()}: {count}\")\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"=\" * 80)\n",
    "    print(\"TOP 10 FINDINGS (by confidence score)\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    sorted_results = sorted(results, key=lambda x: x.get(\"confidence_score\", 0), reverse=True)\n",
    "\n",
    "    for i, r in enumerate(sorted_results[:10], 1):\n",
    "        print(\"\")\n",
    "        print(f\"{i}. {r['subdomain']}\")\n",
    "        print(f\"   CNAME: {r.get('cname', 'N/A')}\")\n",
    "        print(f\"   HTTP Status: {r.get('http_status', 'N/A')}\")\n",
    "        print(f\"   Risk Level: {r.get('risk_level', 'N/A')}\")\n",
    "        print(f\"   Confidence Score: {r.get('confidence_score', 0)}\")\n",
    "        if r.get(\"cname_chain\"):\n",
    "            print(f\"   CNAME Chain: {' → '.join(r['cname_chain'][:3])}\")\n",
    "else:\n",
    "    print(f\"✗ Results file not found: {results_file}\")\n",
    "    print(\"\")\n",
    "    print(\"Make sure Cell 8 completed successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 10: Export to CSV\n",
    "\n",
    "Exports results to `shopify_results.csv` for easy analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_DIR = Path(\"/kaggle/working/subdomain-playground\")\n",
    "if not PROJECT_DIR.exists():\n",
    "    PROJECT_DIR = Path.cwd()\n",
    "\n",
    "results_file = PROJECT_DIR / \"data/scans/shopify_takeover_candidates.json\"\n",
    "if not results_file.exists():\n",
    "    raise SystemExit(f\"✗ Results file not found: {results_file}. Run the scan first.\")\n",
    "\n",
    "with results_file.open(\"r\") as f:\n",
    "    results = json.load(f)\n",
    "\n",
    "if not results:\n",
    "    raise SystemExit(\"✗ No results to export. Make sure the scan produced findings.\")\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# Select key columns\n",
    "columns = [\n",
    "    \"subdomain\", \"cname\", \"http_status\", \"risk_level\", \"confidence_score\",\n",
    "    \"cname_chain_count\", \"final_cname_target\", \"a_records\", \"provider\"\n",
    "]\n",
    "df_export = df[[col for col in columns if col in df.columns]]\n",
    "df_export = df_export.sort_values(\"confidence_score\", ascending=False)\n",
    "\n",
    "# Save to CSV\n",
    "output_csv = PROJECT_DIR / \"shopify_results.csv\"\n",
    "df_export.to_csv(output_csv, index=False)\n",
    "\n",
    "print(f\"✓ Exported {len(df_export)} results to {output_csv}\")\n",
    "print(\"\n",
    "Preview (top 10):\")\n",
    "display(df_export.head(10))\n",
    "\n",
    "print(\"\n",
    "Column descriptions:\")\n",
    "print(\"  - subdomain: Domain scanned\")\n",
    "print(\"  - cname: CNAME record pointing to Shopify\")\n",
    "print(\"  - http_status: HTTP response code (403/404 = potential takeover)\")\n",
    "print(\"  - risk_level: low, medium, high, or critical\")\n",
    "print(\"  - confidence_score: 0-100 (higher = more confident)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 11: Filter High-Risk Only\n",
    "\n",
    "Creates a separate CSV with only critical and high-risk findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_DIR = Path(\"/kaggle/working/subdomain-playground\")\n",
    "if not PROJECT_DIR.exists():\n",
    "    PROJECT_DIR = Path.cwd()\n",
    "\n",
    "results_csv = PROJECT_DIR / \"shopify_results.csv\"\n",
    "if not results_csv.exists():\n",
    "    raise SystemExit(f\"✗ Results CSV not found: {results_csv}. Run the export cell first.\")\n",
    "\n",
    "df = pd.read_csv(results_csv)\n",
    "df_high = df[df[\"risk_level\"].isin([\"critical\", \"high\"])]\n",
    "\n",
    "print(f\"High-risk findings: {len(df_high)} out of {len(df)} total\")\n",
    "print(\"\")\n",
    "\n",
    "if len(df_high) > 0:\n",
    "    high_risk_csv = PROJECT_DIR / \"shopify_high_risk.csv\"\n",
    "    df_high.to_csv(high_risk_csv, index=False)\n",
    "    print(f\"✓ Saved to {high_risk_csv}\")\n",
    "    print(\"\n",
    "High-risk results:\")\n",
    "    display(df_high)\n",
    "    \n",
    "    print(\"\n",
    "⚠️ PRIORITY ACTIONS:\")\n",
    "    print(\"  1. Verify these findings manually\")\n",
    "    print(\"  2. Check if you own these domains\")\n",
    "    print(\"  3. Claim Shopify stores if authorized\")\n",
    "    print(\"  4. Report findings to domain owners\")\n",
    "else:\n",
    "    print(\"✓ No high-risk findings detected.\")\n",
    "    print(\"\n",
    "This is good news! Either:\")\n",
    "    print(\"  - No critical vulnerabilities found\")\n",
    "    print(\"  - All findings are low/medium risk\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 12: Download Results\n",
    "\n",
    "Provides download links for all result files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import FileLink, display\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_DIR = Path(\"/kaggle/working/subdomain-playground\")\n",
    "if not PROJECT_DIR.exists():\n",
    "    PROJECT_DIR = Path.cwd()\n",
    "\n",
    "print(\"Download your results:\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\")\n",
    "\n",
    "files = [\n",
    "    (PROJECT_DIR / \"shopify_results.csv\", \"All Shopify takeover candidates (CSV)\"),\n",
    "    (PROJECT_DIR / \"shopify_high_risk.csv\", \"High-risk findings only (CSV)\"),\n",
    "    (PROJECT_DIR / \"data/scans/shopify_takeover_candidates.json\", \"Full results with metadata (JSON)\")\n",
    "]\n",
    "\n",
    "for file_path, description in files:\n",
    "    if file_path.exists():\n",
    "        file_size = file_path.stat().st_size\n",
    "        size_kb = file_size / 1024\n",
    "        print(f\"✓ {description}\")\n",
    "        print(f\"  Size: {size_kb:.1f} KB\")\n",
    "        display(FileLink(str(file_path)))\n",
    "        print(\"\")\n",
    "    else:\n",
    "        print(f\"- {description} (not found)\")\n",
    "        print(\"\")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"\n",
    "✅ SCAN COMPLETE!\")\n",
    "print(\"\n",
    "Next steps:\")\n",
    "print(\"  1. Download the CSV files above\")\n",
    "print(\"  2. Review high-risk findings first\")\n",
    "print(\"  3. Manually verify critical findings\")\n",
    "print(\"  4. Take appropriate action on confirmed vulnerabilities\")\n",
    "print(\"\n",
    "⚠️ Legal reminder: Only act on domains you own or have authorization to test.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}