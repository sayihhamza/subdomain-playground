{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Shopify Subdomain Takeover Scanner - Dataset-Based\n",
        "\n",
        "**Simple workflow:**\n",
        "1. Load CSV dataset\n",
        "2. Filter by HTTP status (403, 404, 409, 500, 503)\n",
        "3. Sort by Est Monthly Page Views (highest traffic first)\n",
        "4. Export top N targets\n",
        "5. Deep scan with validation tools\n",
        "\n",
        "**Total time:** 15-20 minutes for 100 domains\n",
        "\n",
        "**Dataset:** `/kaggle/input/all-leads-merged/results.csv`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 1: Clone Project from GitHub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash\n",
        "WORKDIR=\"/kaggle/working\"\n",
        "PROJECT_DIR=\"$WORKDIR/subdomain-playground\"\n",
        "\n",
        "echo \"==========================================\"\n",
        "echo \"Cloning Project from GitHub\"\n",
        "echo \"==========================================\"\n",
        "\n",
        "mkdir -p \"$WORKDIR\"\n",
        "cd \"$WORKDIR\"\n",
        "\n",
        "if [ -d \"$PROJECT_DIR\" ]; then\n",
        "    echo \"Removing existing copy...\"\n",
        "    rm -rf \"$PROJECT_DIR\"\n",
        "fi\n",
        "\n",
        "git clone --depth 1 https://github.com/sayihhamza/subdomain-playground.git subdomain-playground\n",
        "\n",
        "if [ ! -d \"$PROJECT_DIR\" ]; then\n",
        "    echo \"‚úó Clone failed!\"\n",
        "    exit 1\n",
        "fi\n",
        "\n",
        "cd \"$PROJECT_DIR\"\n",
        "\n",
        "echo \"\"\n",
        "echo \"‚úì Project cloned successfully!\"\n",
        "echo \"\"\n",
        "echo \"Key files:\"\n",
        "ls -lh scan.py hybrid_scan.py 2>/dev/null || echo \"Files available\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 2: Install Python Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash\n",
        "cd /kaggle/working/subdomain-playground\n",
        "\n",
        "echo \"Installing Python requirements...\"\n",
        "python3 -m pip install --quiet -r requirements.txt\n",
        "\n",
        "echo \"\"\n",
        "echo \"‚úì Dependencies installed!\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 3: Install Go 1.24"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash\n",
        "cd /tmp\n",
        "\n",
        "if command -v sudo >/dev/null 2>&1; then\n",
        "    SUDO=\"sudo\"\n",
        "else\n",
        "    SUDO=\"\"\n",
        "fi\n",
        "\n",
        "echo \"==========================================\"\n",
        "echo \"Installing Go 1.24.1\"\n",
        "echo \"==========================================\"\n",
        "\n",
        "$SUDO rm -rf /usr/local/go 2>/dev/null || true\n",
        "\n",
        "echo \"Downloading Go 1.24.1...\"\n",
        "wget -q https://go.dev/dl/go1.24.1.linux-amd64.tar.gz -O /tmp/go.tar.gz\n",
        "\n",
        "$SUDO tar -C /usr/local -xzf /tmp/go.tar.gz\n",
        "rm -f /tmp/go.tar.gz\n",
        "\n",
        "echo \"\"\n",
        "echo \"‚úì Go 1.24.1 installed!\"\n",
        "/usr/local/go/bin/go version"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 4: Build Security Tools\n",
        "\n",
        "**Building 5 tools (5-8 minutes):**\n",
        "- subfinder: Passive enumeration\n",
        "- findomain: Additional coverage (+5-10%)\n",
        "- dnsx: DNS + CNAME validation\n",
        "- httpx: HTTP validation\n",
        "- subzy: Takeover detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash\n",
        "export PATH=/usr/local/go/bin:$PATH\n",
        "cd /kaggle/working/subdomain-playground\n",
        "\n",
        "echo \"==========================================\"\n",
        "echo \"Building Security Tools (5-8 minutes)\"\n",
        "echo \"==========================================\"\n",
        "echo \"\"\n",
        "\n",
        "mkdir -p bin\n",
        "\n",
        "build_tool() {\n",
        "    local name=$1\n",
        "    local repo=$2\n",
        "    local index=$3\n",
        "    local max_attempts=3\n",
        "    \n",
        "    echo \"[$index/5] Building $name...\"\n",
        "    \n",
        "    for attempt in $(seq 1 $max_attempts); do\n",
        "        if [ $attempt -gt 1 ]; then\n",
        "            echo \"  Retry $attempt/$max_attempts...\"\n",
        "            sleep 2\n",
        "        fi\n",
        "        \n",
        "        if GOBIN=$(pwd)/bin /usr/local/go/bin/go install -v ${repo}@latest 2>&1; then\n",
        "            if [ -f \"bin/$name\" ]; then\n",
        "                echo \"  ‚úì $name built successfully\"\n",
        "                return 0\n",
        "            fi\n",
        "        fi\n",
        "    done\n",
        "    \n",
        "    echo \"  ‚úó Failed to build $name\"\n",
        "    return 1\n",
        "}\n",
        "\n",
        "build_tool \"subfinder\" \"github.com/projectdiscovery/subfinder/v2/cmd/subfinder\" \"1\"\n",
        "echo \"\"\n",
        "\n",
        "build_tool \"findomain\" \"github.com/Findomain/Findomain\" \"2\" || echo \"  ‚ö†Ô∏è Findomain failed (optional)\"\n",
        "echo \"\"\n",
        "\n",
        "build_tool \"dnsx\" \"github.com/projectdiscovery/dnsx/cmd/dnsx\" \"3\"\n",
        "echo \"\"\n",
        "\n",
        "build_tool \"httpx\" \"github.com/projectdiscovery/httpx/cmd/httpx\" \"4\"\n",
        "echo \"\"\n",
        "\n",
        "build_tool \"subzy\" \"github.com/PentestPad/subzy\" \"5\"\n",
        "echo \"\"\n",
        "\n",
        "echo \"==========================================\"\n",
        "echo \"Verification\"\n",
        "echo \"==========================================\"\n",
        "\n",
        "REQUIRED=\"subfinder dnsx httpx subzy\"\n",
        "TOOLS_OK=true\n",
        "\n",
        "for tool in $REQUIRED; do\n",
        "    if [ -f \"bin/$tool\" ]; then\n",
        "        echo \"  ‚úì bin/$tool\"\n",
        "    else\n",
        "        echo \"  ‚úó bin/$tool MISSING\"\n",
        "        TOOLS_OK=false\n",
        "    fi\n",
        "done\n",
        "\n",
        "[ -f \"bin/findomain\" ] && echo \"  ‚úì bin/findomain (bonus!)\" || echo \"  ‚ö†Ô∏è bin/findomain (optional)\"\n",
        "\n",
        "if [ \"$TOOLS_OK\" = false ]; then\n",
        "    echo \"\"\n",
        "    echo \"‚ö†Ô∏è Required tools failed - re-run this cell\"\n",
        "    exit 1\n",
        "fi\n",
        "\n",
        "echo \"\"\n",
        "echo \"‚úì All required tools built!\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 5: Set Environment Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ['SUBFINDER_PATH'] = '/kaggle/working/subdomain-playground/bin/subfinder'\n",
        "os.environ['FINDOMAIN_PATH'] = '/kaggle/working/subdomain-playground/bin/findomain'\n",
        "os.environ['DNSX_PATH'] = '/kaggle/working/subdomain-playground/bin/dnsx'\n",
        "os.environ['HTTPX_PATH'] = '/kaggle/working/subdomain-playground/bin/httpx'\n",
        "os.environ['SUBZY_PATH'] = '/kaggle/working/subdomain-playground/bin/subzy'\n",
        "\n",
        "os.chdir('/kaggle/working/subdomain-playground')\n",
        "\n",
        "print(\"‚úì Environment configured\")\n",
        "print(f\"‚úì Working directory: {os.getcwd()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 6: Load and Filter Dataset\n",
        "\n",
        "**This cell:**\n",
        "1. Loads the CSV dataset\n",
        "2. Filters for Shopify stores\n",
        "3. Filters by HTTP status (403, 404, 409, 500, 503)\n",
        "4. Sorts by Est Monthly Page Views (descending)\n",
        "5. Shows you the top targets before scanning\n",
        "\n",
        "**You can adjust:**\n",
        "- `LIMIT`: How many domains to scan (default: 100)\n",
        "- `STATUS_CODES`: Which HTTP codes to filter (default: [403, 404, 409, 500, 503])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# ========================================\n",
        "# CONFIGURATION - ADJUST THESE\n",
        "# ========================================\n",
        "LIMIT = 100  # How many top domains to scan\n",
        "STATUS_CODES = [403, 404, 409, 500, 503]  # HTTP status codes to target\n",
        "SORT_BY = 'Est Monthly Page Views'  # Column to sort by\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"LOADING DATASET\")\n",
        "print(\"=\" * 80)\n",
        "print(\"\")\n",
        "\n",
        "# Load CSV\n",
        "csv_path = '/kaggle/input/all-leads-merged/results.csv'\n",
        "print(f\"Loading: {csv_path}\")\n",
        "df = pd.read_csv(csv_path, low_memory=False)\n",
        "print(f\"‚úì Loaded {len(df):,} total rows\")\n",
        "print(\"\")\n",
        "\n",
        "# Filter for Shopify\n",
        "print(\"Filtering for Shopify stores...\")\n",
        "df_shopify = df[df['Is_Shopify'].astype(str).str.strip().str.lower() == 'yes']\n",
        "print(f\"‚úì Shopify stores: {len(df_shopify):,}\")\n",
        "\n",
        "# Filter out *.myshopify.com\n",
        "df_custom = df_shopify[~df_shopify['Subdomain'].astype(str).str.contains('myshopify.com', na=False)]\n",
        "print(f\"‚úì Custom domains (not *.myshopify.com): {len(df_custom):,}\")\n",
        "print(\"\")\n",
        "\n",
        "# Filter by HTTP status\n",
        "print(f\"Filtering by HTTP status: {STATUS_CODES}\")\n",
        "df_filtered = df_custom[df_custom['HTTP_Status'].isin(STATUS_CODES)]\n",
        "print(f\"‚úì Matches: {len(df_filtered):,}\")\n",
        "print(\"\")\n",
        "\n",
        "# Status breakdown\n",
        "print(\"Status code breakdown:\")\n",
        "for status in STATUS_CODES:\n",
        "    count = len(df_filtered[df_filtered['HTTP_Status'] == status])\n",
        "    print(f\"  {status}: {count:,}\")\n",
        "print(\"\")\n",
        "\n",
        "# Sort by page views\n",
        "print(f\"Sorting by: {SORT_BY} (highest first)\")\n",
        "\n",
        "if SORT_BY in df_filtered.columns:\n",
        "    # Convert to numeric\n",
        "    df_filtered['PageViews_Numeric'] = pd.to_numeric(\n",
        "        df_filtered[SORT_BY].astype(str).str.replace(r'[^\\d.]', '', regex=True),\n",
        "        errors='coerce'\n",
        "    )\n",
        "    df_filtered['PageViews_Numeric'].fillna(0, inplace=True)\n",
        "    \n",
        "    # Sort and take top N\n",
        "    df_sorted = df_filtered.nlargest(LIMIT, 'PageViews_Numeric')\n",
        "    print(f\"‚úì Sorted {len(df_filtered):,} domains\")\n",
        "else:\n",
        "    print(f\"‚ö†Ô∏è Column '{SORT_BY}' not found - using unsorted data\")\n",
        "    df_sorted = df_filtered.head(LIMIT)\n",
        "\n",
        "print(\"\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"TOP {LIMIT} TARGETS (Highest Traffic)\")\n",
        "print(\"=\" * 80)\n",
        "print(\"\")\n",
        "\n",
        "# Display top 20\n",
        "display_cols = ['Subdomain', 'HTTP_Status', SORT_BY, 'CNAME_Record']\n",
        "display_cols = [col for col in display_cols if col in df_sorted.columns]\n",
        "\n",
        "print(\"Top 20:\")\n",
        "print(df_sorted[display_cols].head(20).to_string(index=False))\n",
        "print(\"\")\n",
        "print(f\"... and {len(df_sorted) - 20} more\" if len(df_sorted) > 20 else \"\")\n",
        "print(\"\")\n",
        "\n",
        "# Export to file\n",
        "targets_file = '/kaggle/working/scan_targets.txt'\n",
        "df_sorted['Subdomain'].to_csv(targets_file, index=False, header=False)\n",
        "print(f\"‚úì Exported {len(df_sorted)} targets to: {targets_file}\")\n",
        "print(\"\")\n",
        "\n",
        "# Also save CSV for reference\n",
        "csv_file = '/kaggle/working/filtered_targets.csv'\n",
        "df_sorted[display_cols].to_csv(csv_file, index=False)\n",
        "print(f\"‚úì Saved filtered data to: {csv_file}\")\n",
        "print(\"\")\n",
        "print(\"=\" * 80)\n",
        "print(\"Next: Run Cell 7 to scan these targets\")\n",
        "print(\"=\" * 80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 7: Deep Scanner Validation (10-15 minutes)\n",
        "\n",
        "**Scans the filtered targets with:**\n",
        "- DNS validation (CNAME chains)\n",
        "- HTTP validation (body analysis)\n",
        "- Takeover detection (subzy)\n",
        "- CNAME blacklist filtering (46 patterns)\n",
        "- Cloudflare verification detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import subprocess\n",
        "import sys\n",
        "import time\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"DEEP SCANNER VALIDATION\")\n",
        "print(\"=\" * 80)\n",
        "print(\"\")\n",
        "print(\"Scanning: /kaggle/working/scan_targets.txt\")\n",
        "print(\"Mode: quick (skips enumeration - already subdomains)\")\n",
        "print(\"Workers: 2 (optimized for Kaggle)\")\n",
        "print(\"\")\n",
        "print(\"Features:\")\n",
        "print(\"  ‚úì Automatic subdomain detection\")\n",
        "print(\"  ‚úì CNAME blacklist (46 patterns)\")\n",
        "print(\"  ‚úì Cloudflare verification detection\")\n",
        "print(\"  ‚úì Custom DNS resolvers\")\n",
        "print(\"  ‚úì Tools: subfinder + findomain + dnsx + httpx + subzy\")\n",
        "print(\"\")\n",
        "\n",
        "scan_start = time.time()\n",
        "\n",
        "scan_cmd = [\n",
        "    sys.executable, '-u', 'scan.py',\n",
        "    '-l', '/kaggle/working/scan_targets.txt',\n",
        "    '--mode', 'quick',\n",
        "    '--provider', 'Shopify',\n",
        "    '--require-cname',\n",
        "    '--filter-status', '3*,4*,5*',\n",
        "    '--workers', '2',\n",
        "    '--json',\n",
        "    '--output', '/kaggle/working/takeover_results.json'\n",
        "]\n",
        "\n",
        "scan_proc = subprocess.Popen(\n",
        "    scan_cmd,\n",
        "    stdout=subprocess.PIPE,\n",
        "    stderr=subprocess.STDOUT,\n",
        "    universal_newlines=True,\n",
        "    bufsize=1\n",
        ")\n",
        "\n",
        "for line in iter(scan_proc.stdout.readline, ''):\n",
        "    if line:\n",
        "        print(line, end='', flush=True)\n",
        "\n",
        "scan_proc.wait()\n",
        "scan_time = time.time() - scan_start\n",
        "\n",
        "print(\"\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"‚úì Scan Complete in {scan_time/60:.1f} minutes\")\n",
        "print(\"=\" * 80)\n",
        "print(\"\")\n",
        "print(\"‚úì Results: /kaggle/working/takeover_results.json\")\n",
        "print(\"\")\n",
        "print(\"Next: Run Cell 8 to view results\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 8: View Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "results_file = Path('/kaggle/working/takeover_results.json')\n",
        "\n",
        "if not results_file.exists():\n",
        "    print(\"‚ùå Results file not found!\")\n",
        "    print(\"Make sure Cell 7 completed successfully\")\n",
        "else:\n",
        "    with open(results_file) as f:\n",
        "        results = json.load(f)\n",
        "    \n",
        "    print(\"=\" * 80)\n",
        "    print(\"SCAN RESULTS\")\n",
        "    print(\"=\" * 80)\n",
        "    print(\"\")\n",
        "    print(f\"Total analyzed: {len(results)}\")\n",
        "    \n",
        "    definite = [r for r in results if 'DEFINITE' in r.get('evidence', '')]\n",
        "    high_prob = [r for r in results if 'HIGH PROBABILITY' in r.get('evidence', '')]\n",
        "    false_pos = [r for r in results if 'FALSE POSITIVE' in r.get('evidence', '')]\n",
        "    \n",
        "    print(\"\")\n",
        "    print(\"Breakdown:\")\n",
        "    print(f\"  üî¥ DEFINITE TAKEOVER: {len(definite)}\")\n",
        "    print(f\"  ‚ö†Ô∏è  HIGH PROBABILITY: {len(high_prob)}\")\n",
        "    print(f\"  ‚ùå FALSE POSITIVE: {len(false_pos)}\")\n",
        "    \n",
        "    print(\"\")\n",
        "    print(\"=\" * 80)\n",
        "    print(\"TOP 10 VULNERABILITIES\")\n",
        "    print(\"=\" * 80)\n",
        "    \n",
        "    if definite:\n",
        "        df = pd.DataFrame(definite)\n",
        "        df_sorted = df.sort_values('confidence', ascending=False) if 'confidence' in df.columns else df\n",
        "        \n",
        "        for i, row in df_sorted.head(10).iterrows():\n",
        "            print(\"\")\n",
        "            print(f\"{i+1}. {row['subdomain']}\")\n",
        "            print(f\"   Status: {row.get('status', 'N/A')}\")\n",
        "            print(f\"   CNAME: {row.get('cname', 'N/A')}\")\n",
        "            print(f\"   Evidence: {row.get('evidence', 'N/A')}\")\n",
        "            print(f\"   Confidence: {row.get('confidence', 0)}\")\n",
        "    else:\n",
        "        print(\"\")\n",
        "        print(\"No definite takeovers found.\")\n",
        "        print(\"Check HIGH PROBABILITY results.\")\n",
        "    \n",
        "    print(\"\")\n",
        "    print(\"=\" * 80)\n",
        "    print(\"Next: Run Cell 9 to export CSV\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 9: Export Results to CSV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "results_file = Path('/kaggle/working/takeover_results.json')\n",
        "\n",
        "if results_file.exists():\n",
        "    with open(results_file) as f:\n",
        "        results = json.load(f)\n",
        "    \n",
        "    df = pd.DataFrame(results)\n",
        "    \n",
        "    columns = ['subdomain', 'status', 'cname', 'evidence', 'confidence', 'message']\n",
        "    df_export = df[[col for col in columns if col in df.columns]]\n",
        "    \n",
        "    if 'confidence' in df_export.columns:\n",
        "        df_export = df_export.sort_values('confidence', ascending=False)\n",
        "    \n",
        "    output_csv = Path('/kaggle/working/shopify_takeovers.csv')\n",
        "    df_export.to_csv(output_csv, index=False)\n",
        "    \n",
        "    print(\"=\" * 80)\n",
        "    print(\"CSV EXPORT\")\n",
        "    print(\"=\" * 80)\n",
        "    print(\"\")\n",
        "    print(f\"‚úì Exported {len(df_export)} results to: {output_csv}\")\n",
        "    print(\"\")\n",
        "    print(\"Preview (top 20):\")\n",
        "    print(df_export.head(20).to_string(index=False))\n",
        "    \n",
        "    if len(df_export) > 20:\n",
        "        print(\"\")\n",
        "        print(f\"... and {len(df_export) - 20} more rows\")\n",
        "    \n",
        "    df_high = df_export[df_export['evidence'].str.contains('DEFINITE|HIGH', na=False)]\n",
        "    if len(df_high) > 0:\n",
        "        high_risk_csv = Path('/kaggle/working/shopify_high_risk.csv')\n",
        "        df_high.to_csv(high_risk_csv, index=False)\n",
        "        print(\"\")\n",
        "        print(f\"‚úì High-risk only ({len(df_high)} results): {high_risk_csv}\")\n",
        "    \n",
        "    print(\"\")\n",
        "    print(\"=\" * 80)\n",
        "    print(\"‚úÖ COMPLETE!\")\n",
        "    print(\"=\" * 80)\n",
        "    print(\"\")\n",
        "    print(\"Download files from Kaggle Output section\")\n",
        "else:\n",
        "    print(\"‚ùå Results file not found!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 10: Performance Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\" * 80)\n",
        "print(\"PERFORMANCE SUMMARY\")\n",
        "print(\"=\" * 80)\n",
        "print(\"\")\n",
        "print(\"Workflow:\")\n",
        "print(\"  1. Load 1.7M row CSV dataset\")\n",
        "print(\"  2. Filter by Shopify + HTTP status\")\n",
        "print(\"  3. Sort by Est Monthly Page Views\")\n",
        "print(\"  4. Scan top N targets (default: 100)\")\n",
        "print(\"\")\n",
        "print(\"Time:\")\n",
        "print(\"  Setup (Cells 1-5): 6-10 minutes\")\n",
        "print(\"  Filter (Cell 6): 2-5 seconds\")\n",
        "print(\"  Scan (Cell 7): 10-15 minutes\")\n",
        "print(\"  Total: 15-25 minutes\")\n",
        "print(\"\")\n",
        "print(\"Tools:\")\n",
        "print(\"  ‚úì subfinder (passive enumeration)\")\n",
        "print(\"  ‚úì findomain (bonus coverage)\")\n",
        "print(\"  ‚úì dnsx (DNS + CNAME)\")\n",
        "print(\"  ‚úì httpx (HTTP validation)\")\n",
        "print(\"  ‚úì subzy (takeover detection)\")\n",
        "print(\"\")\n",
        "print(\"Features:\")\n",
        "print(\"  ‚úì Dataset-based (no Google Sheets)\")\n",
        "print(\"  ‚úì Filter by HTTP status\")\n",
        "print(\"  ‚úì Sort by page views\")\n",
        "print(\"  ‚úì CNAME blacklist (46 patterns)\")\n",
        "print(\"  ‚úì Cloudflare verification detection\")\n",
        "print(\"  ‚úì Custom DNS resolvers\")\n",
        "print(\"\")\n",
        "print(\"=\" * 80)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
