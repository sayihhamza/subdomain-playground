{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shopify Subdomain Takeover Scanner\n",
    "\n",
    "**Total time:** ~6 hours for 10,000 domains\n",
    "\n",
    "**What this does:**\n",
    "- Scans domains for Shopify CNAME records\n",
    "- Detects HTTP 403/404 status (potential takeover indicators)\n",
    "- Real-time progress display\n",
    "- Exports results to CSV\n",
    "\n",
    "**Instructions:** Run cells 1-12 in order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 1: Clone Project from GitHub\n",
    "\n",
    "Clones the project repository to Kaggle workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "set -euo pipefail\n",
    "\n",
    "WORKDIR=${KAGGLE_WORKING_DIR:-/kaggle/working}\n",
    "if [ ! -d \"$WORKDIR\" ]; then\n",
    "    WORKDIR=\"$(pwd)\"\n",
    "fi\n",
    "PROJECT_DIR=\"$WORKDIR/subdomain-playground\"\n",
    "\n",
    "echo \"==========================================\"\n",
    "echo \"Cloning Project from GitHub\"\n",
    "echo \"==========================================\"\n",
    "\n",
    "echo \"Working directory: $WORKDIR\"\n",
    "mkdir -p \"$WORKDIR\"\n",
    "cd \"$WORKDIR\"\n",
    "\n",
    "if [ -d \"$PROJECT_DIR\" ]; then\n",
    "    echo \"Removing existing copy at $PROJECT_DIR\"\n",
    "    rm -rf \"$PROJECT_DIR\"\n",
    "fi\n",
    "\n",
    "git clone --depth 1 https://github.com/sayihhamza/subdomain-playground.git \"$PROJECT_DIR\"\n",
    "\n",
    "cd \"$PROJECT_DIR\"\n",
    "\n",
    "echo \"\"\n",
    "echo \"✓ Project cloned successfully!\"\n",
    "echo \"\"\n",
    "echo \"Project structure:\"\n",
    "ls -lh | head -20\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Cell 2: Configure Environment for Kaggle"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "set -euo pipefail\n",
    "\n",
    "WORKDIR=${KAGGLE_WORKING_DIR:-/kaggle/working}\n",
    "if [ ! -d \"$WORKDIR\" ]; then\n",
    "    WORKDIR=\"$(pwd)\"\n",
    "fi\n",
    "PROJECT_DIR=\"$WORKDIR/subdomain-playground\"\n",
    "\n",
    "cd \"$PROJECT_DIR\"\n",
    "\n",
    "echo \"==========================================\"\n",
    "echo \"Verifying Project Files & Python Deps\"\n",
    "echo \"==========================================\"\n",
    "\n",
    "echo \"\"\n",
    "echo \"Essential files:\"\n",
    "ls -lh scan.py requirements.txt 2>/dev/null\n",
    "\n",
    "echo \"\"\n",
    "echo \"Directories:\"\n",
    "ls -d */ 2>/dev/null\n",
    "\n",
    "echo \"\"\n",
    "echo \"CSV files:\"\n",
    "if [ -d \"data/domain_sources/myleadfox\" ]; then\n",
    "    CSV_COUNT=$(ls data/domain_sources/myleadfox/*.csv 2>/dev/null | wc -l)\n",
    "    echo \"✓ Found $CSV_COUNT CSV files in data/domain_sources/myleadfox/\"\n",
    "    ls -lh data/domain_sources/myleadfox/*.csv 2>/dev/null | head -5\n",
    "else\n",
    "    echo \"✗ CSV directory not found\"\n",
    "fi\n",
    "\n",
    "echo \"\"\n",
    "echo \"Installing Python requirements (quiet)...\"\n",
    "python3 -m pip install --quiet -r requirements.txt\n",
    "\n",
    "echo \"\"\n",
    "echo \"✓ Project structure verified!\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Cell 3: Install Go 1.24\n\nKaggle has Go 1.18, but we need Go 1.24+ to compile the latest security tools."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "set -euo pipefail\n",
    "\n",
    "WORKDIR=${KAGGLE_WORKING_DIR:-/kaggle/working}\n",
    "if [ ! -d \"$WORKDIR\" ]; then\n",
    "    WORKDIR=\"$(pwd)\"\n",
    "fi\n",
    "cd \"$WORKDIR\"\n",
    "\n",
    "if command -v sudo >/dev/null 2>&1; then\n",
    "    SUDO=\"sudo\"\n",
    "else\n",
    "    SUDO=\"\"\n",
    "fi\n",
    "\n",
    "echo \"==========================================\"\n",
    "echo \"Installing Go 1.24.1\"\n",
    "echo \"==========================================\"\n",
    "\n",
    "echo \"Current Go version:\"\n",
    "go version 2>/dev/null || echo \"Go not found\"\n",
    "\n",
    "echo \"\"\n",
    "echo \"Installing Go 1.24.1...\"\n",
    "\n",
    "# Remove old Go installations\n",
    "$SUDO rm -rf /usr/lib/go* 2>/dev/null || true\n",
    "$SUDO rm -rf /usr/local/go 2>/dev/null || true\n",
    "\n",
    "# Download Go 1.24.1 - with retry\n",
    "echo \"Downloading Go 1.24.1 for Linux AMD64...\"\n",
    "for i in {1..3}; do\n",
    "    wget -q https://go.dev/dl/go1.24.1.linux-amd64.tar.gz -O /tmp/go.tar.gz && break || sleep 5\n",
    "done\n",
    "\n",
    "# Verify download\n",
    "if [ ! -f /tmp/go.tar.gz ]; then\n",
    "    echo \"✗ Failed to download Go\"\n",
    "    exit 1\n",
    "fi\n",
    "\n",
    "# Install Go\n",
    "echo \"Installing to /usr/local/go...\"\n",
    "$SUDO tar -C /usr/local -xzf /tmp/go.tar.gz\n",
    "\n",
    "# Cleanup\n",
    "rm -f /tmp/go.tar.gz\n",
    "\n",
    "# Verify installation\n",
    "if [ ! -f /usr/local/go/bin/go ]; then\n",
    "    echo \"✗ Go installation failed\"\n",
    "    exit 1\n",
    "fi\n",
    "\n",
    "echo \"\"\n",
    "echo \"✓ Go 1.24.1 installed successfully!\"\n",
    "echo \"\"\n",
    "echo \"New Go version:\"\n",
    "/usr/local/go/bin/go version\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Cell 4: Build Security Tools from Source\n\nCompiles subfinder, httpx, dnsx, and subzy from source. This takes 3-4 minutes.\n\nThese tools are required for:\n- **subfinder**: Passive subdomain enumeration\n- **httpx**: HTTP probing and status checking\n- **dnsx**: DNS resolution and CNAME chain tracking\n- **subzy**: Subdomain takeover detection"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "%%bash\nexport PATH=/usr/local/go/bin:$PATH\ncd /kaggle/working/subdomain-playground\n\necho \"==========================================\"\necho \"Building Security Tools\"\necho \"==========================================\"\necho \"This takes 3-4 minutes...\"\necho \"⏳ Retrying on network errors (Kaggle proxy issues)\"\necho \"\"\n\n# Verify Go is available\nif ! command -v /usr/local/go/bin/go &> /dev/null; then\n    echo \"✗ Go not found! Re-run Cell 3\"\n    exit 1\nfi\n\n# Create bin directory\nmkdir -p bin\n\n# Function to build with retries\nbuild_tool() {\n    local name=$1\n    local repo=$2\n    local max_attempts=3\n    \n    echo \"[$3/4] Building $name...\"\n    \n    for attempt in $(seq 1 $max_attempts); do\n        if [ $attempt -gt 1 ]; then\n            echo \"  Retry $attempt/$max_attempts...\"\n            sleep 2\n        fi\n        \n        if GOBIN=$(pwd)/bin /usr/local/go/bin/go install -v ${repo}@latest 2>&1; then\n            if [ -f \"bin/$name\" ]; then\n                echo \"  ✓ $name built successfully\"\n                return 0\n            fi\n        fi\n    done\n    \n    echo \"  ✗ Failed to build $name after $max_attempts attempts\"\n    return 1\n}\n\n# Build each tool with retries\nbuild_tool \"subfinder\" \"github.com/projectdiscovery/subfinder/v2/cmd/subfinder\" \"1\"\nSUBFINDER_OK=$?\n\necho \"\"\nbuild_tool \"httpx\" \"github.com/projectdiscovery/httpx/cmd/httpx\" \"2\"\nHTTPX_OK=$?\n\necho \"\"\nbuild_tool \"dnsx\" \"github.com/projectdiscovery/dnsx/cmd/dnsx\" \"3\"\nDNSX_OK=$?\n\necho \"\"\nbuild_tool \"subzy\" \"github.com/PentestPad/subzy\" \"4\"\nSUBZY_OK=$?\n\necho \"\"\necho \"==========================================\"\necho \"Verification\"\necho \"==========================================\"\n\n# Check results\nTOOLS_OK=true\nfor tool in subfinder httpx dnsx subzy; do\n    if [ -f \"bin/$tool\" ]; then\n        echo \"✓ bin/$tool exists\"\n    else\n        echo \"✗ bin/$tool not found!\"\n        TOOLS_OK=false\n    fi\ndone\n\nif [ \"$TOOLS_OK\" = false ]; then\n    echo \"\"\n    echo \"==========================================\"\n    echo \"⚠️  Some tools failed to build due to network errors\"\n    echo \"==========================================\"\n    echo \"\"\n    echo \"This is a Kaggle network issue (proxy.golang.org timeouts).\"\n    echo \"\"\n    echo \"Solutions:\"\n    echo \"  1. Wait 1-2 minutes and re-run this cell\"\n    echo \"  2. If it keeps failing, restart the Kaggle session\"\n    echo \"  3. Try running at a different time (less network congestion)\"\n    exit 1\nfi\n\necho \"\"\necho \"Tool versions:\"\n./bin/subfinder -version 2>&1 | head -1 || echo \"subfinder: installed\"\n./bin/httpx -version 2>&1 | head -1 || echo \"httpx: installed\"\n./bin/dnsx -version 2>&1 | head -1 || echo \"dnsx: installed\"\n./bin/subzy --help 2>&1 | head -1 || echo \"subzy: installed\"\n\necho \"\"\necho \"Binary details:\"\nfile bin/subfinder | cut -d: -f2\nfile bin/httpx | cut -d: -f2\nfile bin/dnsx | cut -d: -f2\nfile bin/subzy | cut -d: -f2\n\necho \"\"\necho \"Tool sizes:\"\nls -lh bin/ | grep -E \"(subfinder|httpx|dnsx|subzy)\" | awk '{print $9 \": \" $5}'\n\necho \"\"\necho \"✓ All tools built successfully!\""
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Cell 5: Verify Environment\n\nVerifies that .env file exists with correct tool paths (now included in repo)."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "%%bash\ncd /kaggle/working/subdomain-playground\n\necho \"Verifying .env file...\"\necho \"\"\n\nif [ -f \".env\" ]; then\n    echo \"✓ .env file exists\"\n    echo \"\"\n    echo \"Contents:\"\n    cat .env\nelse\n    echo \"✗ .env file not found - creating it now...\"\n    cat > .env << 'EOF'\nSUBFINDER_PATH=/kaggle/working/subdomain-playground/bin/subfinder\nDNSX_PATH=/kaggle/working/subdomain-playground/bin/dnsx\nHTTPX_PATH=/kaggle/working/subdomain-playground/bin/httpx\nSUBZY_PATH=/kaggle/working/subdomain-playground/bin/subzy\nEOF\n    echo \"✓ .env file created\"\nfi\n\necho \"\"\necho \"Verifying tool paths:\"\nfor tool in subfinder dnsx httpx subzy; do\n    if [ -f \"bin/$tool\" ]; then\n        echo \"✓ bin/$tool exists\"\n    else\n        echo \"✗ bin/$tool NOT FOUND\"\n    fi\ndone"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 6: Extract Domains from CSV Files\n",
    "\n",
    "Extracts unique domains from CSV files in `data/domain_sources/myleadfox/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "set -euo pipefail\n",
    "\n",
    "WORKDIR=${KAGGLE_WORKING_DIR:-/kaggle/working}\n",
    "if [ ! -d \"$WORKDIR\" ]; then\n",
    "    WORKDIR=\"$(pwd)\"\n",
    "fi\n",
    "PROJECT_DIR=\"$WORKDIR/subdomain-playground\"\n",
    "cd \"$PROJECT_DIR\"\n",
    "\n",
    "echo \"==========================================\"\n",
    "echo \"Extracting Domains from CSV Files\"\n",
    "echo \"==========================================\"\n",
    "\n",
    "if [ -d \"data/domain_sources/myleadfox\" ]; then\n",
    "    CSV_COUNT=$(ls data/domain_sources/myleadfox/*.csv 2>/dev/null | wc -l)\n",
    "    echo \"Found $CSV_COUNT CSV files\"\n",
    "    echo \"\"\n",
    "\n",
    "    # Extract unique domains from all CSV files\n",
    "    echo \"Extracting domains...\"\n",
    "    cat data/domain_sources/myleadfox/*.csv |       tail -n +2 |       cut -d',' -f1 |       sed 's/\"//g' |       grep -E '^[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$' |       sort -u > data/all_sources.txt\n",
    "\n",
    "    DOMAIN_COUNT=$(wc -l < data/all_sources.txt | tr -d ' ')\n",
    "    echo \"✓ Extracted $DOMAIN_COUNT unique domains\"\n",
    "    echo \"\"\n",
    "    echo \"Saved to: data/all_sources.txt\"\n",
    "    echo \"\"\n",
    "    echo \"First 10 domains:\"\n",
    "    head -10 data/all_sources.txt\n",
    "else\n",
    "    echo \"✗ CSV directory not found: data/domain_sources/myleadfox/\"\n",
    "    echo \"Please add your CSV files to this directory\"\n",
    "    exit 1\n",
    "fi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 7: Quick Test (5 domains)\n",
    "\n",
    "**⚠️ IMPORTANT: Watch for real-time output!**\n",
    "\n",
    "You should see:\n",
    "- Domains streaming with DNS/HTTP info\n",
    "- Live progress updates\n",
    "- CNAME chains and provider detection\n",
    "\n",
    "If Cell 7 works correctly, you can proceed to Cell 8 for the full scan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import subprocess\nimport sys\nimport os\n\n# Change to project directory\nos.chdir('/kaggle/working/subdomain-playground')\n\n# Add bin to PATH\nos.environ['PATH'] = f\"/kaggle/working/subdomain-playground/bin:{os.environ['PATH']}\"\n\n# Set tool paths\nos.environ['SUBFINDER_PATH'] = '/kaggle/working/subdomain-playground/bin/subfinder'\nos.environ['DNSX_PATH'] = '/kaggle/working/subdomain-playground/bin/dnsx'\nos.environ['HTTPX_PATH'] = '/kaggle/working/subdomain-playground/bin/httpx'\nos.environ['SUBZY_PATH'] = '/kaggle/working/subdomain-playground/bin/subzy'\n\nprint(\"=\" * 80)\nprint(\"Quick Test - 5 Domains\")\nprint(\"=\" * 80)\nprint()\n\n# Verify tools\nprint(\"Verifying tools are in PATH:\")\nfor tool in ['subfinder', 'dnsx', 'httpx', 'subzy']:\n    tool_path = f\"/kaggle/working/subdomain-playground/bin/{tool}\"\n    if os.path.exists(tool_path):\n        print(f\"  ✓ {tool} found\")\n    else:\n        print(f\"  ✗ {tool} NOT FOUND\")\nprint()\n\n# Test dnsx directly\nprint(\"Testing dnsx directly on google.com:\")\ndnsx_test = subprocess.run(\n    ['./bin/dnsx', '-a', '-cname', '-resp', '-json', '-silent'],\n    input='google.com\\n',\n    capture_output=True,\n    text=True,\n    cwd='/kaggle/working/subdomain-playground'\n)\nprint(dnsx_test.stdout[:200] if dnsx_test.stdout else \"No output\")\nprint()\n\n# Create test file with domains 10-14\nprint(\"Creating test file with 5 diverse domains...\")\nwith open('data/all_sources.txt', 'r') as f:\n    all_domains = f.readlines()\n    test_domains = all_domains[9:14]  # Lines 10-14 (0-indexed)\n\nwith open('data/test_5.txt', 'w') as f:\n    f.writelines(test_domains)\n\nprint(\"Testing with:\")\nwith open('data/test_5.txt', 'r') as f:\n    print(f.read())\nprint()\n\nprint(\"=\" * 80)\nprint(\"STARTING TEST SCAN (NO FILTERS)\")\nprint(\"=\" * 80)\nprint()\nprint(\"NOTE: Running without filters to see all discovered subdomains...\")\nprint()\n\n# Run scan with real-time output\nprocess = subprocess.Popen(\n    [sys.executable, '-u', 'scan.py', \n     '-l', 'data/test_5.txt',\n     '--workers', '2',\n     '--mode', 'quick'],\n    stdout=subprocess.PIPE,\n    stderr=subprocess.STDOUT,\n    universal_newlines=True,\n    bufsize=1\n)\n\n# Stream output line by line in real-time\nfor line in process.stdout:\n    print(line, end='', flush=True)\n\nprocess.wait()\n\nprint()\nprint(\"=\" * 80)\nprint(\"✓ Test Complete\")\nprint(\"=\" * 80)\nprint()\nprint(\"Did you see ANY subdomains above? If yes, the scanner works!\")\nprint(\"If still 0 subdomains, then enumeration itself is failing.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Cell 8: FULL SCAN - ALL DOMAINS (Full Mode with Shopify CNAME Filter)\n\n⚠️ **WARNING: Full mode takes 10-15 hours for ~10,000 domains!**\n\n**Modes available:**\n- **quick**: Passive enumeration only (5-6 hours) - subfinder only\n- **full**: Active + passive enumeration (10-15 hours) - subfinder + DNS bruteforce + alterx\n\n**What you'll see:**\n- Real-time progress streaming\n- Live DNS/HTTP information  \n- Progress updates every 10 domains\n- ETA (estimated time to completion)\n\n**This cell uses FULL MODE with:**\n- `--mode full`: Active + passive enumeration for maximum subdomain discovery\n- `--require-cname`: Only show domains WITH CNAME records\n- Filter applied: Must contain \"shopify\" in CNAME\n\nKaggle sessions timeout after 12 hours, so full mode may timeout. Use quick mode if needed."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import subprocess\nimport sys\nimport os\n\n# Change to project directory\nos.chdir('/kaggle/working/subdomain-playground')\n\n# Add bin to PATH\nos.environ['PATH'] = f\"/kaggle/working/subdomain-playground/bin:{os.environ['PATH']}\"\n\n# Set tool paths\nos.environ['SUBFINDER_PATH'] = '/kaggle/working/subdomain-playground/bin/subfinder'\nos.environ['DNSX_PATH'] = '/kaggle/working/subdomain-playground/bin/dnsx'\nos.environ['HTTPX_PATH'] = '/kaggle/working/subdomain-playground/bin/httpx'\nos.environ['SUBZY_PATH'] = '/kaggle/working/subdomain-playground/bin/subzy'\n\nprint(\"=\" * 80)\nprint(\"STARTING FULL SCAN - FULL MODE\")\nprint(\"=\" * 80)\nprint()\n\n# Count domains\nwith open('data/all_sources.txt', 'r') as f:\n    domain_count = len(f.readlines())\n\nprint(f\"Total domains: {domain_count}\")\nprint(\"Workers: 4\")\nprint(\"Mode: FULL (active + passive enumeration)\")\nprint(\"Filter: Require CNAME + Shopify domains\")\nprint()\nprint(\"Estimated time: 10-15 hours\")\nprint(\"⚠️  WARNING: May exceed Kaggle 12-hour limit!\")\nprint()\nprint(\"=\" * 80)\nprint()\n\n# Run scan with real-time output\nprocess = subprocess.Popen(\n    [sys.executable, '-u', 'scan.py', \n     '-l', 'data/all_sources.txt',\n     '--mode', 'full',\n     '--require-cname',\n     '--provider', 'Shopify',\n     '--workers', '4'],\n    stdout=subprocess.PIPE,\n    stderr=subprocess.STDOUT,\n    universal_newlines=True,\n    bufsize=1\n)\n\n# Stream output line by line in real-time\nfor line in process.stdout:\n    print(line, end='', flush=True)\n\nprocess.wait()\nprint()\nprint(\"Scan completed with return code:\", process.returncode)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 9: View Results Summary\n",
    "\n",
    "Displays scan results with risk level breakdown and top findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_DIR = Path(\"/kaggle/working/subdomain-playground\")\n",
    "if not PROJECT_DIR.exists():\n",
    "    PROJECT_DIR = Path.cwd()\n",
    "\n",
    "results_file = PROJECT_DIR / \"data/scans/shopify_takeover_candidates.json\"\n",
    "\n",
    "if results_file.exists():\n",
    "    with results_file.open(\"r\") as f:\n",
    "        results = json.load(f)\n",
    "\n",
    "    print(\"=\" * 80)\n",
    "    print(\"SHOPIFY TAKEOVER SCAN RESULTS\")\n",
    "    print(\"=\" * 80)\n",
    "    print(\"\")\n",
    "    print(f\"Total candidates found: {len(results)}\")\n",
    "\n",
    "    # Count by risk level\n",
    "    risk_counts = {}\n",
    "    for r in results:\n",
    "        risk = r.get(\"risk_level\", \"unknown\")\n",
    "        risk_counts[risk] = risk_counts.get(risk, 0) + 1\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Breakdown by risk level:\")\n",
    "    for risk, count in sorted(risk_counts.items()):\n",
    "        print(f\"  {risk.upper()}: {count}\")\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"=\" * 80)\n",
    "    print(\"TOP 10 FINDINGS (by confidence score)\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    sorted_results = sorted(results, key=lambda x: x.get(\"confidence_score\", 0), reverse=True)\n",
    "\n",
    "    for i, r in enumerate(sorted_results[:10], 1):\n",
    "        print(\"\")\n",
    "        print(f\"{i}. {r['subdomain']}\")\n",
    "        print(f\"   CNAME: {r.get('cname', 'N/A')}\")\n",
    "        print(f\"   HTTP Status: {r.get('http_status', 'N/A')}\")\n",
    "        print(f\"   Risk Level: {r.get('risk_level', 'N/A')}\")\n",
    "        print(f\"   Confidence Score: {r.get('confidence_score', 0)}\")\n",
    "        if r.get(\"cname_chain\"):\n",
    "            print(f\"   CNAME Chain: {' → '.join(r['cname_chain'][:3])}\")\n",
    "else:\n",
    "    print(f\"✗ Results file not found: {results_file}\")\n",
    "    print(\"\")\n",
    "    print(\"Make sure Cell 8 completed successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 10: Export to CSV\n",
    "\n",
    "Exports results to `shopify_results.csv` for easy analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_DIR = Path(\"/kaggle/working/subdomain-playground\")\n",
    "if not PROJECT_DIR.exists():\n",
    "    PROJECT_DIR = Path.cwd()\n",
    "\n",
    "results_file = PROJECT_DIR / \"data/scans/shopify_takeover_candidates.json\"\n",
    "if not results_file.exists():\n",
    "    raise SystemExit(f\"✗ Results file not found: {results_file}. Run the scan first.\")\n",
    "\n",
    "with results_file.open(\"r\") as f:\n",
    "    results = json.load(f)\n",
    "\n",
    "if not results:\n",
    "    raise SystemExit(\"✗ No results to export. Make sure the scan produced findings.\")\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# Select key columns\n",
    "columns = [\n",
    "    \"subdomain\", \"cname\", \"http_status\", \"risk_level\", \"confidence_score\",\n",
    "    \"cname_chain_count\", \"final_cname_target\", \"a_records\", \"provider\"\n",
    "]\n",
    "df_export = df[[col for col in columns if col in df.columns]]\n",
    "df_export = df_export.sort_values(\"confidence_score\", ascending=False)\n",
    "\n",
    "# Save to CSV\n",
    "output_csv = PROJECT_DIR / \"shopify_results.csv\"\n",
    "df_export.to_csv(output_csv, index=False)\n",
    "\n",
    "print(f\"✓ Exported {len(df_export)} results to {output_csv}\")\n",
    "print(\"\n",
    "Preview (top 10):\")\n",
    "display(df_export.head(10))\n",
    "\n",
    "print(\"\n",
    "Column descriptions:\")\n",
    "print(\"  - subdomain: Domain scanned\")\n",
    "print(\"  - cname: CNAME record pointing to Shopify\")\n",
    "print(\"  - http_status: HTTP response code (403/404 = potential takeover)\")\n",
    "print(\"  - risk_level: low, medium, high, or critical\")\n",
    "print(\"  - confidence_score: 0-100 (higher = more confident)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 11: Filter High-Risk Only\n",
    "\n",
    "Creates a separate CSV with only critical and high-risk findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_DIR = Path(\"/kaggle/working/subdomain-playground\")\n",
    "if not PROJECT_DIR.exists():\n",
    "    PROJECT_DIR = Path.cwd()\n",
    "\n",
    "results_csv = PROJECT_DIR / \"shopify_results.csv\"\n",
    "if not results_csv.exists():\n",
    "    raise SystemExit(f\"✗ Results CSV not found: {results_csv}. Run the export cell first.\")\n",
    "\n",
    "df = pd.read_csv(results_csv)\n",
    "df_high = df[df[\"risk_level\"].isin([\"critical\", \"high\"])]\n",
    "\n",
    "print(f\"High-risk findings: {len(df_high)} out of {len(df)} total\")\n",
    "print(\"\")\n",
    "\n",
    "if len(df_high) > 0:\n",
    "    high_risk_csv = PROJECT_DIR / \"shopify_high_risk.csv\"\n",
    "    df_high.to_csv(high_risk_csv, index=False)\n",
    "    print(f\"✓ Saved to {high_risk_csv}\")\n",
    "    print(\"\n",
    "High-risk results:\")\n",
    "    display(df_high)\n",
    "    \n",
    "    print(\"\n",
    "⚠️ PRIORITY ACTIONS:\")\n",
    "    print(\"  1. Verify these findings manually\")\n",
    "    print(\"  2. Check if you own these domains\")\n",
    "    print(\"  3. Claim Shopify stores if authorized\")\n",
    "    print(\"  4. Report findings to domain owners\")\n",
    "else:\n",
    "    print(\"✓ No high-risk findings detected.\")\n",
    "    print(\"\n",
    "This is good news! Either:\")\n",
    "    print(\"  - No critical vulnerabilities found\")\n",
    "    print(\"  - All findings are low/medium risk\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 12: Download Results\n",
    "\n",
    "Provides download links for all result files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import FileLink, display\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_DIR = Path(\"/kaggle/working/subdomain-playground\")\n",
    "if not PROJECT_DIR.exists():\n",
    "    PROJECT_DIR = Path.cwd()\n",
    "\n",
    "print(\"Download your results:\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\")\n",
    "\n",
    "files = [\n",
    "    (PROJECT_DIR / \"shopify_results.csv\", \"All Shopify takeover candidates (CSV)\"),\n",
    "    (PROJECT_DIR / \"shopify_high_risk.csv\", \"High-risk findings only (CSV)\"),\n",
    "    (PROJECT_DIR / \"data/scans/shopify_takeover_candidates.json\", \"Full results with metadata (JSON)\")\n",
    "]\n",
    "\n",
    "for file_path, description in files:\n",
    "    if file_path.exists():\n",
    "        file_size = file_path.stat().st_size\n",
    "        size_kb = file_size / 1024\n",
    "        print(f\"✓ {description}\")\n",
    "        print(f\"  Size: {size_kb:.1f} KB\")\n",
    "        display(FileLink(str(file_path)))\n",
    "        print(\"\")\n",
    "    else:\n",
    "        print(f\"- {description} (not found)\")\n",
    "        print(\"\")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"\n",
    "✅ SCAN COMPLETE!\")\n",
    "print(\"\n",
    "Next steps:\")\n",
    "print(\"  1. Download the CSV files above\")\n",
    "print(\"  2. Review high-risk findings first\")\n",
    "print(\"  3. Manually verify critical findings\")\n",
    "print(\"  4. Take appropriate action on confirmed vulnerabilities\")\n",
    "print(\"\n",
    "⚠️ Legal reminder: Only act on domains you own or have authorization to test.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}