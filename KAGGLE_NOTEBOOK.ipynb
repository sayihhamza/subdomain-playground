{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shopify Subdomain Takeover Scanner\n",
    "\n",
    "**Dataset-based workflow:**\n",
    "1. Load CSV dataset (`/kaggle/input/all-leads-merged/results.csv`)\n",
    "2. Filter: Shopify stores + exclude myshopify.com + exclude 200/429\n",
    "3. Sort by Est Monthly Page Views (highest traffic first)\n",
    "4. Select range to scan (e.g., rows 1-100)\n",
    "5. Deep scan with full mode\n",
    "\n",
    "**Total time:** ~7-9 hours for 10,000 domains (within Kaggle's 12-hour limit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 1: Clone Project from GitHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "WORKDIR=\"/kaggle/working\"\n",
    "PROJECT_DIR=\"$WORKDIR/subdomain-playground\"\n",
    "\n",
    "echo \"==========================================\"\n",
    "echo \"Cloning Project from GitHub\"\n",
    "echo \"==========================================\"\n",
    "\n",
    "mkdir -p \"$WORKDIR\"\n",
    "cd \"$WORKDIR\"\n",
    "\n",
    "if [ -d \"$PROJECT_DIR\" ]; then\n",
    "    echo \"Removing existing copy...\"\n",
    "    rm -rf \"$PROJECT_DIR\"\n",
    "fi\n",
    "\n",
    "git clone --depth 1 https://github.com/sayihhamza/subdomain-playground.git subdomain-playground\n",
    "\n",
    "if [ ! -d \"$PROJECT_DIR\" ]; then\n",
    "    echo \"âœ— Clone failed!\"\n",
    "    exit 1\n",
    "fi\n",
    "\n",
    "cd \"$PROJECT_DIR\"\n",
    "\n",
    "echo \"\"\n",
    "echo \"âœ“ Project cloned successfully!\"\n",
    "echo \"\"\n",
    "echo \"Project structure:\"\n",
    "ls -lh | head -20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 2: Install Python Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd /kaggle/working/subdomain-playground\n",
    "\n",
    "echo \"Installing Python requirements...\"\n",
    "python3 -m pip install --quiet -r requirements.txt\n",
    "\n",
    "echo \"\"\n",
    "echo \"âœ“ Dependencies installed!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 3: Install Go 1.24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd /tmp\n",
    "\n",
    "if command -v sudo >/dev/null 2>&1; then\n",
    "    SUDO=\"sudo\"\n",
    "else\n",
    "    SUDO=\"\"\n",
    "fi\n",
    "\n",
    "echo \"==========================================\"\n",
    "echo \"Installing Go 1.24.1\"\n",
    "echo \"==========================================\"\n",
    "\n",
    "$SUDO rm -rf /usr/local/go 2>/dev/null || true\n",
    "\n",
    "echo \"Downloading Go 1.24.1...\"\n",
    "for i in {1..3}; do\n",
    "    wget -q https://go.dev/dl/go1.24.1.linux-amd64.tar.gz -O /tmp/go.tar.gz && break || sleep 5\n",
    "done\n",
    "\n",
    "if [ ! -f /tmp/go.tar.gz ]; then\n",
    "    echo \"âœ— Failed to download Go\"\n",
    "    exit 1\n",
    "fi\n",
    "\n",
    "$SUDO tar -C /usr/local -xzf /tmp/go.tar.gz\n",
    "rm -f /tmp/go.tar.gz\n",
    "\n",
    "echo \"\"\n",
    "echo \"âœ“ Go 1.24.1 installed!\"\n",
    "/usr/local/go/bin/go version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 4: Build Security Tools\n",
    "\n",
    "Builds 5 tools (5-8 minutes):\n",
    "- **subfinder**: Passive subdomain enumeration\n",
    "- **findomain**: Additional passive enumeration (optional)\n",
    "- **httpx**: HTTP validation\n",
    "- **dnsx**: DNS + CNAME validation\n",
    "- **subzy**: Takeover detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export PATH=/usr/local/go/bin:$PATH\n",
    "cd /kaggle/working/subdomain-playground\n",
    "\n",
    "echo \"==========================================\"\n",
    "echo \"Building Security Tools\"\n",
    "echo \"==========================================\"\n",
    "echo \"\"\n",
    "\n",
    "mkdir -p bin\n",
    "\n",
    "# Build Go tools\n",
    "build_tool() {\n",
    "    local name=$1\n",
    "    local repo=$2\n",
    "    local index=$3\n",
    "    local total=$4\n",
    "    local max_attempts=3\n",
    "    \n",
    "    echo \"[$index/$total] Building $name...\"\n",
    "    \n",
    "    for attempt in $(seq 1 $max_attempts); do\n",
    "        if [ $attempt -gt 1 ]; then\n",
    "            echo \"  Retry $attempt/$max_attempts...\"\n",
    "            sleep 2\n",
    "        fi\n",
    "        \n",
    "        if GOBIN=$(pwd)/bin /usr/local/go/bin/go install -v ${repo}@latest 2>&1; then\n",
    "            if [ -f \"bin/$name\" ]; then\n",
    "                echo \"  âœ“ $name built successfully\"\n",
    "                return 0\n",
    "            fi\n",
    "        fi\n",
    "    done\n",
    "    \n",
    "    echo \"  âœ— Failed to build $name\"\n",
    "    return 1\n",
    "}\n",
    "\n",
    "# Download precompiled binary\n",
    "download_binary() {\n",
    "    local name=$1\n",
    "    local url=$2\n",
    "    local index=$3\n",
    "    local total=$4\n",
    "    local max_attempts=3\n",
    "    \n",
    "    echo \"[$index/$total] Downloading $name...\"\n",
    "    \n",
    "    for attempt in $(seq 1 $max_attempts); do\n",
    "        if [ $attempt -gt 1 ]; then\n",
    "            echo \"  Retry $attempt/$max_attempts...\"\n",
    "            sleep 2\n",
    "        fi\n",
    "        \n",
    "        if curl -sL \"$url\" -o /tmp/${name}.zip 2>&1; then\n",
    "            if unzip -q /tmp/${name}.zip -d bin/ 2>&1; then\n",
    "                if [ -f \"bin/$name\" ]; then\n",
    "                    chmod +x \"bin/$name\"\n",
    "                    echo \"  âœ“ $name downloaded successfully\"\n",
    "                    rm -f /tmp/${name}.zip\n",
    "                    return 0\n",
    "                fi\n",
    "            fi\n",
    "        fi\n",
    "    done\n",
    "    \n",
    "    echo \"  âš ï¸  $name download failed (optional)\"\n",
    "    rm -f /tmp/${name}.zip\n",
    "    return 1\n",
    "}\n",
    "\n",
    "# Build required tools\n",
    "build_tool \"subfinder\" \"github.com/projectdiscovery/subfinder/v2/cmd/subfinder\" \"1\" \"5\"\n",
    "echo \"\"\n",
    "\n",
    "download_binary \"findomain\" \"https://github.com/Findomain/Findomain/releases/latest/download/findomain-linux-i386.zip\" \"2\" \"5\"\n",
    "echo \"\"\n",
    "\n",
    "build_tool \"httpx\" \"github.com/projectdiscovery/httpx/cmd/httpx\" \"3\" \"5\"\n",
    "echo \"\"\n",
    "\n",
    "build_tool \"dnsx\" \"github.com/projectdiscovery/dnsx/cmd/dnsx\" \"4\" \"5\"\n",
    "echo \"\"\n",
    "\n",
    "build_tool \"subzy\" \"github.com/PentestPad/subzy\" \"5\" \"5\"\n",
    "echo \"\"\n",
    "\n",
    "echo \"==========================================\"\n",
    "echo \"Verification\"\n",
    "echo \"==========================================\"\n",
    "\n",
    "REQUIRED=\"subfinder httpx dnsx subzy\"\n",
    "TOOLS_OK=true\n",
    "\n",
    "for tool in $REQUIRED; do\n",
    "    if [ -f \"bin/$tool\" ]; then\n",
    "        echo \"  âœ“ bin/$tool\"\n",
    "    else\n",
    "        echo \"  âœ— bin/$tool MISSING\"\n",
    "        TOOLS_OK=false\n",
    "    fi\n",
    "done\n",
    "\n",
    "[ -f \"bin/findomain\" ] && echo \"  âœ“ bin/findomain (bonus!)\" || echo \"  âš ï¸  bin/findomain (optional)\"\n",
    "\n",
    "if [ \"$TOOLS_OK\" = false ]; then\n",
    "    echo \"\"\n",
    "    echo \"âš ï¸  Required tools failed - re-run this cell\"\n",
    "    exit 1\n",
    "fi\n",
    "\n",
    "echo \"\"\n",
    "echo \"âœ“ All required tools built!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 5: Set Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['SUBFINDER_PATH'] = '/kaggle/working/subdomain-playground/bin/subfinder'\n",
    "os.environ['FINDOMAIN_PATH'] = '/kaggle/working/subdomain-playground/bin/findomain'\n",
    "os.environ['DNSX_PATH'] = '/kaggle/working/subdomain-playground/bin/dnsx'\n",
    "os.environ['HTTPX_PATH'] = '/kaggle/working/subdomain-playground/bin/httpx'\n",
    "os.environ['SUBZY_PATH'] = '/kaggle/working/subdomain-playground/bin/subzy'\n",
    "\n",
    "os.chdir('/kaggle/working/subdomain-playground')\n",
    "\n",
    "print(\"âœ“ Environment configured\")\n",
    "print(f\"âœ“ Working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 6: Load and Sort Dataset\n",
    "\n",
    "**Configuration:**\n",
    "- `SORT_BY`: Column to sort by (default: 'Est Monthly Page Views')\n",
    "\n",
    "**What this cell does:**\n",
    "1. Loads the full CSV dataset\n",
    "2. Sorts by specified column (descending)\n",
    "3. Creates `df_base_filtered` for Cell 7 and Cell 8\n",
    "\n",
    "**Note:** NO filtering here. Cell 7 and Cell 8 apply their own filters independently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import pandas as pd\n\n# ========================================\n# CONFIGURATION\n# ========================================\nSORT_BY = 'Est Monthly Page Views'  # Column to sort by\n\nprint(\"=\" * 80)\nprint(\"LOADING AND SORTING DATASET\")\nprint(\"=\" * 80)\nprint(\"\")\n\n# Load CSV from Kaggle input\ncsv_path = '/kaggle/input/all-leads-merged/results.csv'\nprint(f\"Loading: {csv_path}\")\ndf = pd.read_csv(csv_path, low_memory=False)\nprint(f\"âœ“ Loaded {len(df):,} total rows\")\nprint(\"\")\n\n# Sort by specified column (NO FILTERING)\nprint(f\"Sorting by: {SORT_BY} (descending)\")\nif SORT_BY in df.columns:\n    # Convert to numeric if it's a numeric column\n    df['_sort_numeric'] = pd.to_numeric(\n        df[SORT_BY].astype(str).str.replace(r'[^\\d.]', '', regex=True),\n        errors='coerce'\n    ).fillna(0)\n    df_sorted = df.sort_values('_sort_numeric', ascending=False)\n    print(f\"âœ“ Sorted by {SORT_BY}\")\nelse:\n    print(f\"âš ï¸  Column '{SORT_BY}' not found - using unsorted\")\n    df_sorted = df\nprint(\"\")\n\n# Store base dataset for Cell 7 (preview) and Cell 8 (scan)\ndf_base_filtered = df_sorted.copy()\n\nprint(\"=\" * 80)\nprint(\"âœ“ Dataset loaded and sorted\")\nprint(f\"Total available: {len(df_base_filtered):,} rows\")\nprint(\"\")\nprint(\"Next steps:\")\nprint(\"  â€¢ Cell 7: Apply filters + preview range\")\nprint(\"  â€¢ Cell 8: Apply filters + scan range\")\nprint(\"=\" * 80)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 7: Preview Dataset (Manual Review)\n",
    "\n",
    "**INDEPENDENT RANGE CONTROL:**\n",
    "- Configure `PREVIEW_START_ROW` and `PREVIEW_END_ROW` below\n",
    "- Works from the sorted dataset (`df_base_filtered` from Cell 6)\n",
    "\n",
    "**Filters applied (for preview only):**\n",
    "1. Is_Shopify == 'Yes'\n",
    "2. Exclude *.myshopify.com domains\n",
    "3. Exclude HTTP 200 and 429\n",
    "\n",
    "**Use this to:**\n",
    "- Verify the filtered data looks correct before scanning\n",
    "- Check specific subdomains manually\n",
    "- Preview different ranges than what you scan in Cell 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ========================================\n",
    "# PREVIEW CONFIGURATION (Cell 7 only)\n",
    "# ========================================\n",
    "PREVIEW_START_ROW = 1       # First row to preview (1-indexed)\n",
    "PREVIEW_END_ROW = 100       # Last row to preview\n",
    "\n",
    "print(\"=\" * 120)\n",
    "print(f\"PREVIEW: Rows {PREVIEW_START_ROW} to {PREVIEW_END_ROW} from Sorted Dataset\")\n",
    "print(\"=\" * 120)\n",
    "print(\"\")\n",
    "print(f\"Source: df_base_filtered from Cell 6 (sorted by {SORT_BY})\")\n",
    "print(f\"Total available: {len(df_base_filtered):,} rows\")\n",
    "print(\"\")\n",
    "\n",
    "# Select preview range from base dataset (sorted, but unfiltered)\n",
    "df_preview = df_base_filtered.iloc[PREVIEW_START_ROW-1:PREVIEW_END_ROW].copy()\n",
    "print(f\"Selected range: {len(df_preview)} rows\")\n",
    "print(\"\")\n",
    "\n",
    "# Apply preview filters (for display only)\n",
    "print(\"Applying filters for preview...\")\n",
    "\n",
    "# Filter A: Shopify stores only\n",
    "is_shopify = df_preview['Is_Shopify'] == 'Yes'\n",
    "print(f\"  After Shopify filter: {is_shopify.sum()} rows\")\n",
    "\n",
    "# Filter B: Exclude raw 'myshopify.com' domains\n",
    "is_custom_domain = ~df_preview['Subdomain'].str.contains('myshopify.com', case=False, na=False)\n",
    "print(f\"  After myshopify.com exclusion: {(is_shopify & is_custom_domain).sum()} rows\")\n",
    "\n",
    "# Filter C: Exclude HTTP 200 and 429\n",
    "excluded_statuses = [200, 429, '200', '429', 200.0, 429.0]\n",
    "is_interesting_status = ~df_preview['HTTP_Status'].isin(excluded_statuses)\n",
    "print(f\"  After status exclusion: {(is_shopify & is_custom_domain & is_interesting_status).sum()} rows\")\n",
    "\n",
    "# Apply all filters\n",
    "df_preview_filtered = df_preview[is_shopify & is_custom_domain & is_interesting_status].copy()\n",
    "print(\"\")\n",
    "\n",
    "# Prepare display with original row numbers\n",
    "display_df = df_preview_filtered.copy()\n",
    "# Calculate actual row numbers from base dataset\n",
    "actual_rows = []\n",
    "for idx in display_df.index:\n",
    "    actual_row = df_base_filtered.index.get_loc(idx) + 1\n",
    "    actual_rows.append(actual_row)\n",
    "display_df.insert(0, 'Row', actual_rows)\n",
    "\n",
    "# Select columns to display\n",
    "display_columns = ['Row', 'Subdomain', 'HTTP_Status', SORT_BY, 'CNAME_Record']\n",
    "display_columns = [col for col in display_columns if col in display_df.columns]\n",
    "\n",
    "print(\"=\" * 120)\n",
    "print(f\"Displaying {len(display_df)} domains after filters:\")\n",
    "print(\"=\" * 120)\n",
    "print(\"\")\n",
    "\n",
    "# Configure pandas display\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', 50)\n",
    "pd.set_option('display.width', 120)\n",
    "\n",
    "# Display\n",
    "print(display_df[display_columns].to_string(index=False))\n",
    "\n",
    "print(\"\")\n",
    "print(\"=\" * 120)\n",
    "print(\"ðŸ“‹ Preview Summary:\")\n",
    "print(f\"  â€¢ Preview range: Rows {PREVIEW_START_ROW} to {PREVIEW_END_ROW}\")\n",
    "print(f\"  â€¢ After filters: {len(display_df)} domains\")\n",
    "print(f\"  â€¢ Sorted by: {SORT_BY} (highest first)\")\n",
    "print(f\"  â€¢ Filters: Shopify + Custom domain + Exclude status 200/429\")\n",
    "print(\"\")\n",
    "print(\"ðŸ’¡ NOTE: Cell 8 scans ALL domains in range (scan.py applies its own filters)\")\n",
    "print(\"=\" * 120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 8: Deep Scan Execution\n",
    "\n",
    "**INDEPENDENT RANGE CONTROL:**\n",
    "- Configure `SCAN_START_ROW` and `SCAN_END_ROW` below\n",
    "- Works from the sorted dataset (`df_base_filtered` from Cell 6)\n",
    "\n",
    "**NO FILTERS APPLIED HERE** - scan.py handles all filtering:\n",
    "- `--require-cname-contains shopify` (checks CNAME chain)\n",
    "- `--filter-status 3*,4*,5*` (only 3xx/4xx/5xx statuses)\n",
    "\n",
    "**Scan configuration:**\n",
    "- Mode: `full` (active + passive enumeration)\n",
    "- Workers: 2 (optimized for Kaggle)\n",
    "\n",
    "**Note:** Since inputs are already subdomains, the scanner will skip enumeration and go directly to DNS/HTTP validation\n",
    "\n",
    "**Estimated time:** 7-9 hours for 10k domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# ========================================\n",
    "# SCAN CONFIGURATION (Cell 8 only)\n",
    "# ========================================\n",
    "SCAN_START_ROW = 1       # First row to scan (1-indexed)\n",
    "SCAN_END_ROW = 100       # Last row to scan\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"PREPARING SCAN\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\")\n",
    "print(f\"Source: df_base_filtered from Cell 6 (sorted by {SORT_BY})\")\n",
    "print(f\"Total available: {len(df_base_filtered):,} rows\")\n",
    "print(\"\")\n",
    "\n",
    "# Select scan range from base dataset (NO FILTERING - scan.py handles it)\n",
    "df_scan = df_base_filtered.iloc[SCAN_START_ROW-1:SCAN_END_ROW].copy()\n",
    "print(f\"Scan range: Rows {SCAN_START_ROW} to {SCAN_END_ROW}\")\n",
    "print(f\"Selected: {len(df_scan)} domains\")\n",
    "print(\"\")\n",
    "\n",
    "# Save ALL domains from range to file (no filtering)\n",
    "targets_file = '/kaggle/working/subdomain-playground/data/all_sources.txt'\n",
    "df_scan['Subdomain'].to_csv(targets_file, index=False, header=False)\n",
    "print(f\"âœ“ Saved {len(df_scan)} domains to: {targets_file}\")\n",
    "print(\"\")\n",
    "print(\"ðŸ’¡ NOTE: No filters applied here - scan.py will filter during scan\")\n",
    "print(\"\")\n",
    "\n",
    "# Change to project directory\n",
    "os.chdir('/kaggle/working/subdomain-playground')\n",
    "\n",
    "# Add bin to PATH\n",
    "os.environ['PATH'] = f\"/kaggle/working/subdomain-playground/bin:{os.environ['PATH']}\"\n",
    "\n",
    "# Set tool paths\n",
    "os.environ['SUBFINDER_PATH'] = '/kaggle/working/subdomain-playground/bin/subfinder'\n",
    "os.environ['FINDOMAIN_PATH'] = '/kaggle/working/subdomain-playground/bin/findomain'\n",
    "os.environ['DNSX_PATH'] = '/kaggle/working/subdomain-playground/bin/dnsx'\n",
    "os.environ['HTTPX_PATH'] = '/kaggle/working/subdomain-playground/bin/httpx'\n",
    "os.environ['SUBZY_PATH'] = '/kaggle/working/subdomain-playground/bin/subzy'\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"STARTING FULL SCAN - SHOPIFY TAKEOVER DETECTION\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\")\n",
    "\n",
    "# Count domains\n",
    "with open('data/all_sources.txt', 'r') as f:\n",
    "    domain_count = len(f.readlines())\n",
    "\n",
    "print(f\"Total domains: {domain_count}\")\n",
    "print(\"Workers: 2 (optimized for Kaggle 2-core CPU)\")\n",
    "print(\"Mode: FULL (active + passive enumeration)\")\n",
    "print(\"Tools: subfinder + findomain + dnsx + httpx + subzy\")\n",
    "print(\"\")\n",
    "print(\"Filters applied by scan.py:\")\n",
    "print(\"  âœ“ CNAME chain contains 'shopify'\")\n",
    "print(\"  âœ“ HTTP status: 3xx, 4xx, 5xx (takeover indicators)\")\n",
    "print(\"\")\n",
    "print(\"What this finds:\")\n",
    "print(\"  âœ“ Any subdomain with CNAME pointing to Shopify\")\n",
    "print(\"  âœ“ Checks entire CNAME chain (not just first hop)\")\n",
    "print(\"  âœ“ Catches Shopify behind Cloudflare/CDN\")\n",
    "print(\"  âœ“ Only shows domains with takeover-indicating HTTP status\")\n",
    "print(\"\")\n",
    "print(\"Estimated time: 7-9 hours\")\n",
    "print(\"âœ“ Completes within Kaggle 12-hour limit with safety margin\")\n",
    "print(\"\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\")\n",
    "\n",
    "# Run scan with real-time output\n",
    "process = subprocess.Popen(\n",
    "    [sys.executable, '-u', 'scan.py',\n",
    "     '-l', 'data/all_sources.txt',\n",
    "     '--mode', 'full',\n",
    "     '--require-cname-contains', 'shopify',\n",
    "     '--filter-status', '3*,403,404,409,41*,43*,5*',\n",
    "     '--workers', '2'],\n",
    "    stdout=subprocess.PIPE,\n",
    "    stderr=subprocess.STDOUT,\n",
    "    universal_newlines=True,\n",
    "    bufsize=1\n",
    ")\n",
    "\n",
    "# Stream output line by line in real-time\n",
    "for line in process.stdout:\n",
    "    print(line, end='', flush=True)\n",
    "\n",
    "process.wait()\n",
    "print(\"\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Scan completed with return code: {process.returncode}\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 9: View Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "results_file = Path(\"/kaggle/working/subdomain-playground/data/scans/shopify_takeover_candidates.json\")\n",
    "\n",
    "if results_file.exists():\n",
    "    with results_file.open(\"r\") as f:\n",
    "        results = json.load(f)\n",
    "\n",
    "    print(\"=\" * 80)\n",
    "    print(\"SCAN RESULTS\")\n",
    "    print(\"=\" * 80)\n",
    "    print(\"\")\n",
    "    print(f\"Total candidates found: {len(results)}\")\n",
    "\n",
    "    # Count by risk level\n",
    "    risk_counts = {}\n",
    "    for r in results:\n",
    "        risk = r.get(\"risk_level\", \"unknown\")\n",
    "        risk_counts[risk] = risk_counts.get(risk, 0) + 1\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Breakdown by risk:\")\n",
    "    for risk, count in sorted(risk_counts.items()):\n",
    "        print(f\"  {risk.upper()}: {count}\")\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"=\" * 80)\n",
    "    print(\"TOP 10 FINDINGS\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    sorted_results = sorted(results, key=lambda x: x.get(\"confidence_score\", 0), reverse=True)\n",
    "\n",
    "    for i, r in enumerate(sorted_results[:10], 1):\n",
    "        print(\"\")\n",
    "        print(f\"{i}. {r['subdomain']}\")\n",
    "        print(f\"   CNAME: {r.get('cname', 'N/A')}\")\n",
    "        print(f\"   HTTP Status: {r.get('http_status', 'N/A')}\")\n",
    "        print(f\"   Risk: {r.get('risk_level', 'N/A')}\")\n",
    "        print(f\"   Confidence: {r.get('confidence_score', 0)}\")\n",
    "else:\n",
    "    print(f\"âœ— Results file not found: {results_file}\")\n",
    "    print(\"Make sure the scan completed successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 10: Export to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "results_file = Path(\"/kaggle/working/subdomain-playground/data/scans/shopify_takeover_candidates.json\")\n",
    "\n",
    "if not results_file.exists():\n",
    "    print(\"âœ— Results file not found. Run the scan first.\")\n",
    "else:\n",
    "    with results_file.open(\"r\") as f:\n",
    "        results = json.load(f)\n",
    "\n",
    "    if not results:\n",
    "        print(\"âœ— No results to export.\")\n",
    "    else:\n",
    "        df = pd.DataFrame(results)\n",
    "\n",
    "        # Select key columns\n",
    "        columns = [\n",
    "            \"subdomain\", \"cname\", \"http_status\", \"risk_level\", \"confidence_score\",\n",
    "            \"cname_chain_count\", \"final_cname_target\", \"a_records\", \"provider\"\n",
    "        ]\n",
    "        df_export = df[[col for col in columns if col in df.columns]]\n",
    "        df_export = df_export.sort_values(\"confidence_score\", ascending=False)\n",
    "\n",
    "        # Save to CSV\n",
    "        output_csv = Path(\"/kaggle/working/shopify_takeovers.csv\")\n",
    "        df_export.to_csv(output_csv, index=False)\n",
    "\n",
    "        print(\"=\" * 80)\n",
    "        print(\"CSV EXPORT\")\n",
    "        print(\"=\" * 80)\n",
    "        print(\"\")\n",
    "        print(f\"âœ“ Exported {len(df_export)} results to: {output_csv}\")\n",
    "        print(\"\")\n",
    "        print(\"Preview (top 20):\")\n",
    "        print(df_export.head(20).to_string(index=False))\n",
    "        \n",
    "        # High-risk only\n",
    "        df_high = df_export[df_export[\"risk_level\"].isin([\"critical\", \"high\"])]\n",
    "        if len(df_high) > 0:\n",
    "            high_risk_csv = Path(\"/kaggle/working/shopify_high_risk.csv\")\n",
    "            df_high.to_csv(high_risk_csv, index=False)\n",
    "            print(\"\")\n",
    "            print(f\"âœ“ High-risk only ({len(df_high)} results): {high_risk_csv}\")\n",
    "        \n",
    "        print(\"\")\n",
    "        print(\"=\" * 80)\n",
    "        print(\"âœ… COMPLETE!\")\n",
    "        print(\"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}