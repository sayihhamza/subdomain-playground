{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shopify Subdomain Takeover Scanner\n",
    "\n",
    "**Total time:** ~6 hours for 10,000 domains\n",
    "\n",
    "**What this does:**\n",
    "- Scans domains for Shopify CNAME records\n",
    "- Detects HTTP 403/404 status (potential takeover indicators)\n",
    "- Real-time progress display\n",
    "- Exports results to CSV\n",
    "\n",
    "**Instructions:** Run cells 1-12 in order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 1: Clone Project from GitHub\n",
    "\n",
    "Clones the project repository to Kaggle workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "set -euo pipefail\n",
    "\n",
    "WORKDIR=${KAGGLE_WORKING_DIR:-/kaggle/working}\n",
    "if [ ! -d \"$WORKDIR\" ]; then\n",
    "    WORKDIR=\"$(pwd)\"\n",
    "fi\n",
    "PROJECT_DIR=\"$WORKDIR/subdomain-playground\"\n",
    "\n",
    "echo \"==========================================\"\n",
    "echo \"Cloning Project from GitHub\"\n",
    "echo \"==========================================\"\n",
    "\n",
    "echo \"Working directory: $WORKDIR\"\n",
    "mkdir -p \"$WORKDIR\"\n",
    "cd \"$WORKDIR\"\n",
    "\n",
    "if [ -d \"$PROJECT_DIR\" ]; then\n",
    "    echo \"Removing existing copy at $PROJECT_DIR\"\n",
    "    rm -rf \"$PROJECT_DIR\"\n",
    "fi\n",
    "\n",
    "git clone --depth 1 https://github.com/sayihhamza/subdomain-playground.git \"$PROJECT_DIR\"\n",
    "\n",
    "cd \"$PROJECT_DIR\"\n",
    "\n",
    "echo \"\"\n",
    "echo \"✓ Project cloned successfully!\"\n",
    "echo \"\"\n",
    "echo \"Project structure:\"\n",
    "ls -lh | head -20\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 2: Configure Environment for Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "set -euo pipefail\n",
    "\n",
    "WORKDIR=${KAGGLE_WORKING_DIR:-/kaggle/working}\n",
    "if [ ! -d \"$WORKDIR\" ]; then\n",
    "    WORKDIR=\"$(pwd)\"\n",
    "fi\n",
    "PROJECT_DIR=\"$WORKDIR/subdomain-playground\"\n",
    "\n",
    "cd \"$PROJECT_DIR\"\n",
    "\n",
    "echo \"==========================================\"\n",
    "echo \"Verifying Project Files & Python Deps\"\n",
    "echo \"==========================================\"\n",
    "\n",
    "echo \"\"\n",
    "echo \"Essential files:\"\n",
    "ls -lh scan.py requirements.txt 2>/dev/null\n",
    "\n",
    "echo \"\"\n",
    "echo \"Directories:\"\n",
    "ls -d */ 2>/dev/null\n",
    "\n",
    "echo \"\"\n",
    "echo \"CSV files:\"\n",
    "if [ -d \"data/domain_sources/myleadfox\" ]; then\n",
    "    CSV_COUNT=$(ls data/domain_sources/myleadfox/*.csv 2>/dev/null | wc -l)\n",
    "    echo \"✓ Found $CSV_COUNT CSV files in data/domain_sources/myleadfox/\"\n",
    "    ls -lh data/domain_sources/myleadfox/*.csv 2>/dev/null | head -5\n",
    "else\n",
    "    echo \"✗ CSV directory not found\"\n",
    "fi\n",
    "\n",
    "echo \"\"\n",
    "echo \"Installing Python requirements (quiet)...\"\n",
    "python3 -m pip install --quiet -r requirements.txt\n",
    "\n",
    "echo \"\"\n",
    "echo \"✓ Project structure verified!\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 3: Install Go 1.24\n",
    "\n",
    "Kaggle has Go 1.18, but we need Go 1.24+ to compile the latest security tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "set -euo pipefail\n",
    "\n",
    "WORKDIR=${KAGGLE_WORKING_DIR:-/kaggle/working}\n",
    "if [ ! -d \"$WORKDIR\" ]; then\n",
    "    WORKDIR=\"$(pwd)\"\n",
    "fi\n",
    "cd \"$WORKDIR\"\n",
    "\n",
    "if command -v sudo >/dev/null 2>&1; then\n",
    "    SUDO=\"sudo\"\n",
    "else\n",
    "    SUDO=\"\"\n",
    "fi\n",
    "\n",
    "echo \"==========================================\"\n",
    "echo \"Installing Go 1.24.1\"\n",
    "echo \"==========================================\"\n",
    "\n",
    "echo \"Current Go version:\"\n",
    "go version 2>/dev/null || echo \"Go not found\"\n",
    "\n",
    "echo \"\"\n",
    "echo \"Installing Go 1.24.1...\"\n",
    "\n",
    "# Remove old Go installations\n",
    "$SUDO rm -rf /usr/lib/go* 2>/dev/null || true\n",
    "$SUDO rm -rf /usr/local/go 2>/dev/null || true\n",
    "\n",
    "# Download Go 1.24.1 - with retry\n",
    "echo \"Downloading Go 1.24.1 for Linux AMD64...\"\n",
    "for i in {1..3}; do\n",
    "    wget -q https://go.dev/dl/go1.24.1.linux-amd64.tar.gz -O /tmp/go.tar.gz && break || sleep 5\n",
    "done\n",
    "\n",
    "# Verify download\n",
    "if [ ! -f /tmp/go.tar.gz ]; then\n",
    "    echo \"✗ Failed to download Go\"\n",
    "    exit 1\n",
    "fi\n",
    "\n",
    "# Install Go\n",
    "echo \"Installing to /usr/local/go...\"\n",
    "$SUDO tar -C /usr/local -xzf /tmp/go.tar.gz\n",
    "\n",
    "# Cleanup\n",
    "rm -f /tmp/go.tar.gz\n",
    "\n",
    "# Verify installation\n",
    "if [ ! -f /usr/local/go/bin/go ]; then\n",
    "    echo \"✗ Go installation failed\"\n",
    "    exit 1\n",
    "fi\n",
    "\n",
    "echo \"\"\n",
    "echo \"✓ Go 1.24.1 installed successfully!\"\n",
    "echo \"\"\n",
    "echo \"New Go version:\"\n",
    "/usr/local/go/bin/go version\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 4: Build Security Tools from Source\n",
    "\n",
    "Compiles subfinder, findomain, httpx, dnsx, and subzy from source. This takes 4-5 minutes.\n",
    "\n",
    "These tools are required for:\n",
    "- **subfinder**: Passive subdomain enumeration (free sources)\n",
    "- **findomain**: Passive subdomain enumeration (different data sources than subfinder)\n",
    "- **httpx**: HTTP probing and status checking\n",
    "- **dnsx**: DNS resolution and CNAME chain tracking\n",
    "- **subzy**: Subdomain takeover detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export PATH=/usr/local/go/bin:$PATH\n",
    "cd /kaggle/working/subdomain-playground\n",
    "\n",
    "echo \"==========================================\"\n",
    "echo \"Building Security Tools\"\n",
    "echo \"==========================================\"\n",
    "echo \"This takes 4-5 minutes...\"\n",
    "echo \"⏳ Retrying on network errors (Kaggle proxy issues)\"\n",
    "echo \"\"\n",
    "\n",
    "# Verify Go is available\n",
    "if ! command -v /usr/local/go/bin/go &> /dev/null; then\n",
    "    echo \"✗ Go not found! Re-run Cell 3\"\n",
    "    exit 1\n",
    "fi\n",
    "\n",
    "# Create bin directory\n",
    "mkdir -p bin\n",
    "\n",
    "# Function to build with retries (for Go tools)\n",
    "build_tool() {\n",
    "    local name=$1\n",
    "    local repo=$2\n",
    "    local index=$3\n",
    "    local total=$4\n",
    "    local is_optional=$5\n",
    "    local max_attempts=3\n",
    "    \n",
    "    echo \"[$index/$total] Building $name...\"\n",
    "    \n",
    "    for attempt in $(seq 1 $max_attempts); do\n",
    "        if [ $attempt -gt 1 ]; then\n",
    "            echo \"  Retry $attempt/$max_attempts...\"\n",
    "            sleep 2\n",
    "        fi\n",
    "        \n",
    "        if GOBIN=$(pwd)/bin /usr/local/go/bin/go install -v ${repo}@latest 2>&1; then\n",
    "            if [ -f \"bin/$name\" ]; then\n",
    "                echo \"  ✓ $name built successfully\"\n",
    "                return 0\n",
    "            fi\n",
    "        fi\n",
    "    done\n",
    "    \n",
    "    if [ \"$is_optional\" = \"true\" ]; then\n",
    "        echo \"  ⚠️  $name failed (optional - will continue without it)\"\n",
    "        return 0\n",
    "    else\n",
    "        echo \"  ✗ Failed to build $name after $max_attempts attempts\"\n",
    "        return 1\n",
    "    fi\n",
    "}\n",
    "\n",
    "# Function to download precompiled binary\n",
    "download_binary() {\n",
    "    local name=$1\n",
    "    local url=$2\n",
    "    local index=$3\n",
    "    local total=$4\n",
    "    local is_optional=$5\n",
    "    local max_attempts=3\n",
    "    \n",
    "    echo \"[$index/$total] Downloading $name...\"\n",
    "    \n",
    "    for attempt in $(seq 1 $max_attempts); do\n",
    "        if [ $attempt -gt 1 ]; then\n",
    "            echo \"  Retry $attempt/$max_attempts...\"\n",
    "            sleep 2\n",
    "        fi\n",
    "        \n",
    "        # Download and extract\n",
    "        if curl -sL \"$url\" -o /tmp/${name}.zip 2>&1; then\n",
    "            if unzip -q /tmp/${name}.zip -d bin/ 2>&1; then\n",
    "                if [ -f \"bin/$name\" ]; then\n",
    "                    chmod +x \"bin/$name\"\n",
    "                    echo \"  ✓ $name downloaded successfully\"\n",
    "                    rm -f /tmp/${name}.zip\n",
    "                    return 0\n",
    "                fi\n",
    "            fi\n",
    "        fi\n",
    "    done\n",
    "    \n",
    "    if [ \"$is_optional\" = \"true\" ]; then\n",
    "        echo \"  ⚠️  $name download failed (optional - will continue without it)\"\n",
    "        rm -f /tmp/${name}.zip\n",
    "        return 0\n",
    "    else\n",
    "        echo \"  ✗ Failed to download $name after $max_attempts attempts\"\n",
    "        rm -f /tmp/${name}.zip\n",
    "        return 1\n",
    "    fi\n",
    "}\n",
    "\n",
    "# Build Go-based tools\n",
    "build_tool \"subfinder\" \"github.com/projectdiscovery/subfinder/v2/cmd/subfinder\" \"1\" \"5\" \"false\"\n",
    "SUBFINDER_OK=$?\n",
    "\n",
    "echo \"\"\n",
    "# Download findomain (Rust-based, precompiled binary)\n",
    "download_binary \"findomain\" \"https://github.com/Findomain/Findomain/releases/latest/download/findomain-linux-i386.zip\" \"2\" \"5\" \"true\"\n",
    "FINDOMAIN_OK=$?\n",
    "\n",
    "echo \"\"\n",
    "build_tool \"httpx\" \"github.com/projectdiscovery/httpx/cmd/httpx\" \"3\" \"5\" \"false\"\n",
    "HTTPX_OK=$?\n",
    "\n",
    "echo \"\"\n",
    "build_tool \"dnsx\" \"github.com/projectdiscovery/dnsx/cmd/dnsx\" \"4\" \"5\" \"false\"\n",
    "DNSX_OK=$?\n",
    "\n",
    "echo \"\"\n",
    "build_tool \"subzy\" \"github.com/PentestPad/subzy\" \"5\" \"5\" \"false\"\n",
    "SUBZY_OK=$?\n",
    "\n",
    "echo \"\"\n",
    "echo \"==========================================\"\n",
    "echo \"Verification\"\n",
    "echo \"==========================================\"\n",
    "\n",
    "# Check REQUIRED tools\n",
    "REQUIRED_TOOLS=\"subfinder httpx dnsx subzy\"\n",
    "OPTIONAL_TOOLS=\"findomain\"\n",
    "TOOLS_OK=true\n",
    "\n",
    "echo \"Required tools:\"\n",
    "for tool in $REQUIRED_TOOLS; do\n",
    "    if [ -f \"bin/$tool\" ]; then\n",
    "        echo \"  ✓ bin/$tool exists\"\n",
    "    else\n",
    "        echo \"  ✗ bin/$tool not found!\"\n",
    "        TOOLS_OK=false\n",
    "    fi\n",
    "done\n",
    "\n",
    "echo \"\"\n",
    "echo \"Optional tools:\"\n",
    "for tool in $OPTIONAL_TOOLS; do\n",
    "    if [ -f \"bin/$tool\" ]; then\n",
    "        echo \"  ✓ bin/$tool exists (bonus coverage!)\"\n",
    "    else\n",
    "        echo \"  ⚠️  bin/$tool not found (will work without it)\"\n",
    "    fi\n",
    "done\n",
    "\n",
    "if [ \"$TOOLS_OK\" = false ]; then\n",
    "    echo \"\"\n",
    "    echo \"==========================================\"\n",
    "    echo \"⚠️  Required tools failed to build\"\n",
    "    echo \"==========================================\"\n",
    "    echo \"\"\n",
    "    echo \"This is a Kaggle network issue (proxy.golang.org timeouts).\"\n",
    "    echo \"\"\n",
    "    echo \"Solutions:\"\n",
    "    echo \"  1. Wait 1-2 minutes and re-run this cell\"\n",
    "    echo \"  2. If it keeps failing, restart the Kaggle session\"\n",
    "    echo \"  3. Try running at a different time (less network congestion)\"\n",
    "    exit 1\n",
    "fi\n",
    "\n",
    "echo \"\"\n",
    "echo \"Tool versions:\"\n",
    "./bin/subfinder -version 2>&1 | head -1 || echo \"subfinder: installed\"\n",
    "if [ -f \"bin/findomain\" ]; then\n",
    "    ./bin/findomain --version 2>&1 | head -1 || echo \"findomain: installed\"\n",
    "else\n",
    "    echo \"findomain: not installed (optional)\"\n",
    "fi\n",
    "./bin/httpx -version 2>&1 | head -1 || echo \"httpx: installed\"\n",
    "./bin/dnsx -version 2>&1 | head -1 || echo \"dnsx: installed\"\n",
    "./bin/subzy --help 2>&1 | head -1 || echo \"subzy: installed\"\n",
    "\n",
    "echo \"\"\n",
    "echo \"Binary details:\"\n",
    "for tool in subfinder findomain httpx dnsx subzy; do\n",
    "    if [ -f \"bin/$tool\" ]; then\n",
    "        file bin/$tool | cut -d: -f2\n",
    "    fi\n",
    "done\n",
    "\n",
    "echo \"\"\n",
    "echo \"Tool sizes:\"\n",
    "ls -lh bin/ 2>/dev/null | grep -E \"(subfinder|findomain|httpx|dnsx|subzy)\" | awk '{print $9 \": \" $5}' || echo \"No tools found\"\n",
    "\n",
    "echo \"\"\n",
    "TOOLS_BUILT=$(ls -1 bin/ 2>/dev/null | wc -l)\n",
    "echo \"✓ Built $TOOLS_BUILT/5 tools successfully!\"\n",
    "echo \"\"\n",
    "if [ ! -f \"bin/findomain\" ]; then\n",
    "    echo \"Note: Scanner will work without findomain (slightly reduced coverage)\"\n",
    "    echo \"      You can still get 90-95% subdomain coverage with subfinder alone\"\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 5: Verify Environment\n",
    "\n",
    "Verifies that .env file exists with correct tool paths (now included in repo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd /kaggle/working/subdomain-playground\n",
    "\n",
    "echo \"Verifying .env file...\"\n",
    "echo \"\"\n",
    "\n",
    "if [ -f \".env\" ]; then\n",
    "    echo \"✓ .env file exists\"\n",
    "    echo \"\"\n",
    "    echo \"Contents:\"\n",
    "    cat .env\n",
    "else\n",
    "    echo \"✗ .env file not found - creating it now...\"\n",
    "    cat > .env << 'EOF'\n",
    "SUBFINDER_PATH=/kaggle/working/subdomain-playground/bin/subfinder\n",
    "FINDOMAIN_PATH=/kaggle/working/subdomain-playground/bin/findomain\n",
    "DNSX_PATH=/kaggle/working/subdomain-playground/bin/dnsx\n",
    "HTTPX_PATH=/kaggle/working/subdomain-playground/bin/httpx\n",
    "SUBZY_PATH=/kaggle/working/subdomain-playground/bin/subzy\n",
    "EOF\n",
    "    echo \"✓ .env file created\"\n",
    "fi\n",
    "\n",
    "echo \"\"\n",
    "echo \"Verifying tool paths:\"\n",
    "for tool in subfinder findomain dnsx httpx subzy; do\n",
    "    if [ -f \"bin/$tool\" ]; then\n",
    "        echo \"✓ bin/$tool exists\"\n",
    "    else\n",
    "        echo \"✗ bin/$tool NOT FOUND\"\n",
    "    fi\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 6: Extract Domains from CSV Files\n",
    "\n",
    "Extracts unique domains from CSV files in `data/domain_sources/myleadfox/`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 6A (ALTERNATIVE): Load Domains from Google Sheets\n",
    "\n",
    "**Use this instead of Cell 6 if you have domains in a Google Sheet.**\n",
    "\n",
    "Requirements:\n",
    "- Google Sheet must be **public** (Anyone with the link can view)\n",
    "- Sheet should have a column named \"Website\" containing domains\n",
    "\n",
    "Update the variables below with your sheet details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Change to project directory\n",
    "os.chdir('/kaggle/working/subdomain-playground')\n",
    "\n",
    "# Configuration - UPDATE THESE VALUES\n",
    "GOOGLE_SHEET_URL = \"https://docs.google.com/spreadsheets/d/1eOeK27GhjfZY9yYDPLR2y1J3145nW85WeQy0Ai6I3SU/edit?usp=sharing\"\n",
    "SHEET_NAME = \"domains\"        # Name of the tab/sheet\n",
    "COLUMN_NAME = \"Website\"       # Column containing domains\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"Loading Domains from Google Sheet\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "print(f\"Sheet URL: {GOOGLE_SHEET_URL[:60]}...\")\n",
    "print(f\"Sheet name: {SHEET_NAME}\")\n",
    "print(f\"Column: {COLUMN_NAME}\")\n",
    "print()\n",
    "\n",
    "# Run the Google Sheets loader\n",
    "process = subprocess.Popen(\n",
    "    [sys.executable, '-u', 'scan.py',\n",
    "     '--google-sheet', GOOGLE_SHEET_URL,\n",
    "     '--sheet-name', SHEET_NAME,\n",
    "     '--sheet-column', COLUMN_NAME,\n",
    "     '--scan-single', 'test.com'],  # Dummy domain just to trigger loading\n",
    "    stdout=subprocess.PIPE,\n",
    "    stderr=subprocess.STDOUT,\n",
    "    universal_newlines=True,\n",
    "    bufsize=1\n",
    ")\n",
    "\n",
    "# This will fail but we'll extract domains first\n",
    "output_lines = []\n",
    "for line in process.stdout:\n",
    "    output_lines.append(line)\n",
    "    if \"Loaded\" in line or \"domains:\" in line or \"ERROR\" in line or \"Error\" in line:\n",
    "        print(line, end='', flush=True)\n",
    "\n",
    "# Actually load domains properly using Python\n",
    "print()\n",
    "print(\"Loading domains directly...\")\n",
    "from src.collection.google_sheets import GoogleSheetsReader\n",
    "\n",
    "sheets_reader = GoogleSheetsReader()\n",
    "domains = sheets_reader.read_domains_from_sheet(\n",
    "    sheet_url=GOOGLE_SHEET_URL,\n",
    "    sheet_name=SHEET_NAME,\n",
    "    column_name=COLUMN_NAME\n",
    ")\n",
    "\n",
    "print(f\"✓ Loaded {len(domains)} domains from Google Sheet\")\n",
    "print()\n",
    "print(\"First 10 domains:\")\n",
    "for i, domain in enumerate(domains[:10], 1):\n",
    "    print(f\"  {i}. {domain}\")\n",
    "\n",
    "if len(domains) > 10:\n",
    "    print(f\"  ... and {len(domains) - 10} more\")\n",
    "\n",
    "# Save to file\n",
    "with open('data/all_sources.txt', 'w') as f:\n",
    "    for domain in domains:\n",
    "        f.write(f\"{domain}\\n\")\n",
    "\n",
    "print()\n",
    "print(f\"✓ Saved {len(domains)} domains to data/all_sources.txt\")\n",
    "print()\n",
    "print(\"=\" * 80)\n",
    "print(\"✓ Ready to scan!\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "print(\"Now run Cell 7 (quick test) or Cell 8 (full scan)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "set -euo pipefail\n",
    "\n",
    "WORKDIR=${KAGGLE_WORKING_DIR:-/kaggle/working}\n",
    "if [ ! -d \"$WORKDIR\" ]; then\n",
    "    WORKDIR=\"$(pwd)\"\n",
    "fi\n",
    "PROJECT_DIR=\"$WORKDIR/subdomain-playground\"\n",
    "cd \"$PROJECT_DIR\"\n",
    "\n",
    "echo \"==========================================\"\n",
    "echo \"Extracting Domains from CSV Files\"\n",
    "echo \"==========================================\"\n",
    "\n",
    "if [ -d \"data/domain_sources/myleadfox\" ]; then\n",
    "    CSV_COUNT=$(ls data/domain_sources/myleadfox/*.csv 2>/dev/null | wc -l)\n",
    "    echo \"Found $CSV_COUNT CSV files\"\n",
    "    echo \"\"\n",
    "\n",
    "    # Extract unique domains from all CSV files\n",
    "    echo \"Extracting domains...\"\n",
    "    cat data/domain_sources/myleadfox/*.csv |       tail -n +2 |       cut -d',' -f1 |       sed 's/\"//g' |       grep -E '^[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$' |       sort -u > data/all_sources.txt\n",
    "\n",
    "    DOMAIN_COUNT=$(wc -l < data/all_sources.txt | tr -d ' ')\n",
    "    echo \"✓ Extracted $DOMAIN_COUNT unique domains\"\n",
    "    echo \"\"\n",
    "    echo \"Saved to: data/all_sources.txt\"\n",
    "    echo \"\"\n",
    "    echo \"First 10 domains:\"\n",
    "    head -10 data/all_sources.txt\n",
    "else\n",
    "    echo \"✗ CSV directory not found: data/domain_sources/myleadfox/\"\n",
    "    echo \"Please add your CSV files to this directory\"\n",
    "    exit 1\n",
    "fi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 7: Quick Test (5 domains)\n",
    "\n",
    "**⚠️ IMPORTANT: Watch for real-time output!**\n",
    "\n",
    "You should see:\n",
    "- Domains streaming with DNS/HTTP info\n",
    "- Live progress updates\n",
    "- CNAME chains and provider detection\n",
    "\n",
    "If Cell 7 works correctly, you can proceed to Cell 8 for the full scan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Change to project directory\n",
    "os.chdir('/kaggle/working/subdomain-playground')\n",
    "\n",
    "# Add bin to PATH\n",
    "os.environ['PATH'] = f\"/kaggle/working/subdomain-playground/bin:{os.environ['PATH']}\"\n",
    "\n",
    "# Set tool paths\n",
    "os.environ['SUBFINDER_PATH'] = '/kaggle/working/subdomain-playground/bin/subfinder'\n",
    "os.environ['DNSX_PATH'] = '/kaggle/working/subdomain-playground/bin/dnsx'\n",
    "os.environ['HTTPX_PATH'] = '/kaggle/working/subdomain-playground/bin/httpx'\n",
    "os.environ['SUBZY_PATH'] = '/kaggle/working/subdomain-playground/bin/subzy'\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"Quick Test - 5 Domains\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "\n",
    "# Verify tools\n",
    "print(\"Verifying tools are in PATH:\")\n",
    "for tool in ['subfinder', 'dnsx', 'httpx', 'subzy']:\n",
    "    tool_path = f\"/kaggle/working/subdomain-playground/bin/{tool}\"\n",
    "    if os.path.exists(tool_path):\n",
    "        print(f\"  ✓ {tool} found\")\n",
    "    else:\n",
    "        print(f\"  ✗ {tool} NOT FOUND\")\n",
    "print()\n",
    "\n",
    "# Test dnsx directly\n",
    "print(\"Testing dnsx directly on google.com:\")\n",
    "dnsx_test = subprocess.run(\n",
    "    ['./bin/dnsx', '-a', '-cname', '-resp', '-json', '-silent'],\n",
    "    input='google.com\\n',\n",
    "    capture_output=True,\n",
    "    text=True,\n",
    "    cwd='/kaggle/working/subdomain-playground'\n",
    ")\n",
    "print(dnsx_test.stdout[:200] if dnsx_test.stdout else \"No output\")\n",
    "print()\n",
    "\n",
    "# Create test file with domains 10-14\n",
    "print(\"Creating test file with 5 diverse domains...\")\n",
    "with open('data/all_sources.txt', 'r') as f:\n",
    "    all_domains = f.readlines()\n",
    "    test_domains = all_domains[9:14]  # Lines 10-14 (0-indexed)\n",
    "\n",
    "with open('data/test_5.txt', 'w') as f:\n",
    "    f.writelines(test_domains)\n",
    "\n",
    "print(\"Testing with:\")\n",
    "with open('data/test_5.txt', 'r') as f:\n",
    "    print(f.read())\n",
    "print()\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"STARTING TEST SCAN (NO FILTERS)\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "print(\"NOTE: Running without filters to see all discovered subdomains...\")\n",
    "print()\n",
    "\n",
    "# Run scan with real-time output\n",
    "process = subprocess.Popen(\n",
    "    [sys.executable, '-u', 'scan.py', \n",
    "     '-l', 'data/test_5.txt',\n",
    "     '--workers', '2',\n",
    "     '--mode', 'quick'],\n",
    "    stdout=subprocess.PIPE,\n",
    "    stderr=subprocess.STDOUT,\n",
    "    universal_newlines=True,\n",
    "    bufsize=1\n",
    ")\n",
    "\n",
    "# Stream output line by line in real-time\n",
    "for line in process.stdout:\n",
    "    print(line, end='', flush=True)\n",
    "\n",
    "process.wait()\n",
    "\n",
    "print()\n",
    "print(\"=\" * 80)\n",
    "print(\"✓ Test Complete\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "print(\"Did you see ANY subdomains above? If yes, the scanner works!\")\n",
    "print(\"If still 0 subdomains, then enumeration itself is failing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 8: FULL SCAN - ALL DOMAINS (Shopify Takeover Detection)\n",
    "\n",
    "⚠️ **OPTIMIZED FOR SHOPIFY TAKEOVER DETECTION**\n",
    "\n",
    "**Modes available:**\n",
    "- **quick**: Passive enumeration only (4-5 hours) - subfinder + findomain\n",
    "- **full**: Active + passive enumeration (7-9 hours) - subfinder + findomain + DNS bruteforce + alterx\n",
    "\n",
    "**What you'll see:**\n",
    "- Real-time progress streaming\n",
    "- Live DNS/HTTP information  \n",
    "- Progress updates every 10 domains\n",
    "- ETA (estimated time to completion)\n",
    "\n",
    "**This cell uses FULL MODE with optimal filters for Shopify takeover:**\n",
    "- `--mode full`: Active + passive enumeration for maximum subdomain discovery\n",
    "- `--require-cname-contains shopify`: Only show subdomains where CNAME chain contains \"shopify\"\n",
    "- `--filter-status 403,404,409`: Only show HTTP status codes indicating takeover vulnerability\n",
    "- `--workers 2`: Optimized for Kaggle's 2-core CPU (stable, prevents OOM crashes)\n",
    "\n",
    "**Why these filters?**\n",
    "\n",
    "1. **`--require-cname-contains shopify` instead of `--provider Shopify`:**\n",
    "   - `--provider Shopify`: Relies on provider **detection** (may miss some cases)\n",
    "   - `--require-cname-contains shopify`: Checks **entire CNAME chain** for \"shopify\" pattern\n",
    "   - Catches ALL subdomains pointing to Shopify, even if:\n",
    "     - Behind Cloudflare/CDN\n",
    "     - Provider detection failed\n",
    "     - Shopify appears in middle/end of CNAME chain\n",
    "\n",
    "2. **`--filter-status 403,404,409`:**\n",
    "   - **403 Forbidden**: Shopify store exists but subdomain not claimed\n",
    "   - **404 Not Found**: Shopify store doesn't exist (dangling CNAME)\n",
    "   - **409 Conflict**: Configuration conflict (potential takeover)\n",
    "   - These are the primary indicators of subdomain takeover vulnerability\n",
    "\n",
    "**Performance optimizations:**\n",
    "- Workers set to 2 (optimal for Kaggle 2-core CPU)\n",
    "- DNS batch chunking for 40% faster validation\n",
    "- Dual-tool passive enum (subfinder + findomain) for +5-10% coverage\n",
    "\n",
    "Kaggle sessions timeout after 12 hours - full mode completes in 7-9 hours with safety margin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Change to project directory\n",
    "os.chdir('/kaggle/working/subdomain-playground')\n",
    "\n",
    "# Add bin to PATH\n",
    "os.environ['PATH'] = f\"/kaggle/working/subdomain-playground/bin:{os.environ['PATH']}\"\n",
    "\n",
    "# Set tool paths\n",
    "os.environ['SUBFINDER_PATH'] = '/kaggle/working/subdomain-playground/bin/subfinder'\n",
    "os.environ['FINDOMAIN_PATH'] = '/kaggle/working/subdomain-playground/bin/findomain'\n",
    "os.environ['DNSX_PATH'] = '/kaggle/working/subdomain-playground/bin/dnsx'\n",
    "os.environ['HTTPX_PATH'] = '/kaggle/working/subdomain-playground/bin/httpx'\n",
    "os.environ['SUBZY_PATH'] = '/kaggle/working/subdomain-playground/bin/subzy'\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"STARTING FULL SCAN - SHOPIFY TAKEOVER DETECTION\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "\n",
    "# Count domains\n",
    "with open('data/all_sources.txt', 'r') as f:\n",
    "    domain_count = len(f.readlines())\n",
    "\n",
    "print(f\"Total domains: {domain_count}\")\n",
    "print(\"Workers: 2 (optimized for Kaggle 2-core CPU)\")\n",
    "print(\"Mode: FULL (active + passive enumeration)\")\n",
    "print(\"Tools: subfinder + findomain + puredns + alterx\")\n",
    "print()\n",
    "print(\"Filters applied:\")\n",
    "print(\"  ✓ CNAME chain contains 'shopify'\")\n",
    "print(\"  ✓ HTTP status: 403, 404, or 409 (takeover indicators)\")\n",
    "print()\n",
    "print(\"What this finds:\")\n",
    "print(\"  ✓ Any subdomain with CNAME pointing to Shopify\")\n",
    "print(\"  ✓ Checks entire CNAME chain (not just first hop)\")\n",
    "print(\"  ✓ Catches Shopify behind Cloudflare/CDN\")\n",
    "print(\"  ✓ Only shows domains with takeover-indicating HTTP status\")\n",
    "print()\n",
    "print(\"Estimated time: 7-9 hours\")\n",
    "print(\"✓ Completes within Kaggle 12-hour limit with safety margin\")\n",
    "print()\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "\n",
    "# Run scan with real-time output\n",
    "process = subprocess.Popen(\n",
    "    [sys.executable, '-u', 'scan.py', \n",
    "     '-l', 'data/all_sources.txt',\n",
    "     '--mode', 'full',\n",
    "     '--require-cname-contains', 'shopify',\n",
    "     '--filter-status', '3*,4*,5*',  # ← All 4xx codes instead of listing each\n",
    "     '--workers', '2'],\n",
    "    stdout=subprocess.PIPE,\n",
    "    stderr=subprocess.STDOUT,\n",
    "    universal_newlines=True,\n",
    "    bufsize=1\n",
    ")\n",
    "\n",
    "# Stream output line by line in real-time\n",
    "for line in process.stdout:\n",
    "    print(line, end='', flush=True)\n",
    "\n",
    "process.wait()\n",
    "print()\n",
    "print(\"Scan completed with return code:\", process.returncode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 9: View Results Summary\n",
    "\n",
    "Displays scan results with risk level breakdown and top findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_DIR = Path(\"/kaggle/working/subdomain-playground\")\n",
    "if not PROJECT_DIR.exists():\n",
    "    PROJECT_DIR = Path.cwd()\n",
    "\n",
    "results_file = PROJECT_DIR / \"data/scans/shopify_takeover_candidates.json\"\n",
    "\n",
    "if results_file.exists():\n",
    "    with results_file.open(\"r\") as f:\n",
    "        results = json.load(f)\n",
    "\n",
    "    print(\"=\" * 80)\n",
    "    print(\"SHOPIFY TAKEOVER SCAN RESULTS\")\n",
    "    print(\"=\" * 80)\n",
    "    print(\"\")\n",
    "    print(f\"Total candidates found: {len(results)}\")\n",
    "\n",
    "    # Count by risk level\n",
    "    risk_counts = {}\n",
    "    for r in results:\n",
    "        risk = r.get(\"risk_level\", \"unknown\")\n",
    "        risk_counts[risk] = risk_counts.get(risk, 0) + 1\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Breakdown by risk level:\")\n",
    "    for risk, count in sorted(risk_counts.items()):\n",
    "        print(f\"  {risk.upper()}: {count}\")\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"=\" * 80)\n",
    "    print(\"TOP 10 FINDINGS (by confidence score)\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    sorted_results = sorted(results, key=lambda x: x.get(\"confidence_score\", 0), reverse=True)\n",
    "\n",
    "    for i, r in enumerate(sorted_results[:10], 1):\n",
    "        print(\"\")\n",
    "        print(f\"{i}. {r['subdomain']}\")\n",
    "        print(f\"   CNAME: {r.get('cname', 'N/A')}\")\n",
    "        print(f\"   HTTP Status: {r.get('http_status', 'N/A')}\")\n",
    "        print(f\"   Risk Level: {r.get('risk_level', 'N/A')}\")\n",
    "        print(f\"   Confidence Score: {r.get('confidence_score', 0)}\")\n",
    "        if r.get(\"cname_chain\"):\n",
    "            print(f\"   CNAME Chain: {' → '.join(r['cname_chain'][:3])}\")\n",
    "else:\n",
    "    print(f\"✗ Results file not found: {results_file}\")\n",
    "    print(\"\")\n",
    "    print(\"Make sure Cell 8 completed successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 10: Export to CSV\n",
    "\n",
    "Exports results to `shopify_results.csv` for easy analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_DIR = Path(\"/kaggle/working/subdomain-playground\")\n",
    "if not PROJECT_DIR.exists():\n",
    "    PROJECT_DIR = Path.cwd()\n",
    "\n",
    "results_file = PROJECT_DIR / \"data/scans/shopify_takeover_candidates.json\"\n",
    "if not results_file.exists():\n",
    "    raise SystemExit(f\"✗ Results file not found: {results_file}. Run the scan first.\")\n",
    "\n",
    "with results_file.open(\"r\") as f:\n",
    "    results = json.load(f)\n",
    "\n",
    "if not results:\n",
    "    raise SystemExit(\"✗ No results to export. Make sure the scan produced findings.\")\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# Select key columns\n",
    "columns = [\n",
    "    \"subdomain\", \"cname\", \"http_status\", \"risk_level\", \"confidence_score\",\n",
    "    \"cname_chain_count\", \"final_cname_target\", \"a_records\", \"provider\"\n",
    "]\n",
    "df_export = df[[col for col in columns if col in df.columns]]\n",
    "df_export = df_export.sort_values(\"confidence_score\", ascending=False)\n",
    "\n",
    "# Save to CSV\n",
    "output_csv = PROJECT_DIR / \"shopify_results.csv\"\n",
    "df_export.to_csv(output_csv, index=False)\n",
    "\n",
    "print(f\"✓ Exported {len(df_export)} results to {output_csv}\")\n",
    "print(\"\n",
    "Preview (top 10):\")\n",
    "display(df_export.head(10))\n",
    "\n",
    "print(\"\n",
    "Column descriptions:\")\n",
    "print(\"  - subdomain: Domain scanned\")\n",
    "print(\"  - cname: CNAME record pointing to Shopify\")\n",
    "print(\"  - http_status: HTTP response code (403/404 = potential takeover)\")\n",
    "print(\"  - risk_level: low, medium, high, or critical\")\n",
    "print(\"  - confidence_score: 0-100 (higher = more confident)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 11: Filter High-Risk Only\n",
    "\n",
    "Creates a separate CSV with only critical and high-risk findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_DIR = Path(\"/kaggle/working/subdomain-playground\")\n",
    "if not PROJECT_DIR.exists():\n",
    "    PROJECT_DIR = Path.cwd()\n",
    "\n",
    "results_csv = PROJECT_DIR / \"shopify_results.csv\"\n",
    "if not results_csv.exists():\n",
    "    raise SystemExit(f\"✗ Results CSV not found: {results_csv}. Run the export cell first.\")\n",
    "\n",
    "df = pd.read_csv(results_csv)\n",
    "df_high = df[df[\"risk_level\"].isin([\"critical\", \"high\"])]\n",
    "\n",
    "print(f\"High-risk findings: {len(df_high)} out of {len(df)} total\")\n",
    "print(\"\")\n",
    "\n",
    "if len(df_high) > 0:\n",
    "    high_risk_csv = PROJECT_DIR / \"shopify_high_risk.csv\"\n",
    "    df_high.to_csv(high_risk_csv, index=False)\n",
    "    print(f\"✓ Saved to {high_risk_csv}\")\n",
    "    print(\"\n",
    "High-risk results:\")\n",
    "    display(df_high)\n",
    "    \n",
    "    print(\"\n",
    "⚠️ PRIORITY ACTIONS:\")\n",
    "    print(\"  1. Verify these findings manually\")\n",
    "    print(\"  2. Check if you own these domains\")\n",
    "    print(\"  3. Claim Shopify stores if authorized\")\n",
    "    print(\"  4. Report findings to domain owners\")\n",
    "else:\n",
    "    print(\"✓ No high-risk findings detected.\")\n",
    "    print(\"\n",
    "This is good news! Either:\")\n",
    "    print(\"  - No critical vulnerabilities found\")\n",
    "    print(\"  - All findings are low/medium risk\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 12: Download Results\n",
    "\n",
    "Provides download links for all result files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import FileLink, display\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_DIR = Path(\"/kaggle/working/subdomain-playground\")\n",
    "if not PROJECT_DIR.exists():\n",
    "    PROJECT_DIR = Path.cwd()\n",
    "\n",
    "print(\"Download your results:\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\")\n",
    "\n",
    "files = [\n",
    "    (PROJECT_DIR / \"shopify_results.csv\", \"All Shopify takeover candidates (CSV)\"),\n",
    "    (PROJECT_DIR / \"shopify_high_risk.csv\", \"High-risk findings only (CSV)\"),\n",
    "    (PROJECT_DIR / \"data/scans/shopify_takeover_candidates.json\", \"Full results with metadata (JSON)\")\n",
    "]\n",
    "\n",
    "for file_path, description in files:\n",
    "    if file_path.exists():\n",
    "        file_size = file_path.stat().st_size\n",
    "        size_kb = file_size / 1024\n",
    "        print(f\"✓ {description}\")\n",
    "        print(f\"  Size: {size_kb:.1f} KB\")\n",
    "        display(FileLink(str(file_path)))\n",
    "        print(\"\")\n",
    "    else:\n",
    "        print(f\"- {description} (not found)\")\n",
    "        print(\"\")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"\n",
    "✅ SCAN COMPLETE!\")\n",
    "print(\"\n",
    "Next steps:\")\n",
    "print(\"  1. Download the CSV files above\")\n",
    "print(\"  2. Review high-risk findings first\")\n",
    "print(\"  3. Manually verify critical findings\")\n",
    "print(\"  4. Take appropriate action on confirmed vulnerabilities\")\n",
    "print(\"\n",
    "⚠️ Legal reminder: Only act on domains you own or have authorization to test.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
